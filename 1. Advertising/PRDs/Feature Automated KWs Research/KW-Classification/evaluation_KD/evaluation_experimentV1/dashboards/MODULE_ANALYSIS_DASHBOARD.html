<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module Evaluation Analysis Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background-color: #f5f7fa;
            display: flex;
            min-height: 100vh;
        }

        /* Sidebar */
        .sidebar {
            width: 240px;
            background: linear-gradient(180deg, #1a1a2e 0%, #16213e 100%);
            color: white;
            padding: 20px 0;
            position: fixed;
            height: 100vh;
            overflow-y: auto;
        }

        .sidebar-header {
            padding: 0 15px 20px;
            border-bottom: 1px solid rgba(255,255,255,0.1);
            margin-bottom: 10px;
        }

        .sidebar-header h1 {
            font-size: 16px;
            font-weight: 600;
            margin-bottom: 5px;
        }

        .sidebar-header p {
            font-size: 11px;
            opacity: 0.7;
        }

        .dashboard-info {
            margin: 0 15px 15px;
            padding: 12px;
            background: rgba(78, 205, 196, 0.15);
            border-radius: 8px;
            border-left: 3px solid #4ecdc4;
        }

        .dashboard-info h4 {
            font-size: 11px;
            text-transform: uppercase;
            color: #4ecdc4;
            margin-bottom: 6px;
        }

        .dashboard-info p {
            font-size: 10px;
            line-height: 1.5;
            opacity: 0.9;
        }

        .menu-section {
            margin: 15px 0;
            padding-top: 15px;
            border-top: 1px solid rgba(255,255,255,0.1);
        }

        .menu-section-title {
            padding: 0 15px;
            font-size: 10px;
            text-transform: uppercase;
            color: rgba(255,255,255,0.5);
            margin-bottom: 8px;
            letter-spacing: 1px;
        }

        .module-list {
            list-style: none;
        }

        .module-item {
            padding: 10px 15px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: space-between;
            transition: all 0.2s ease;
            border-left: 3px solid transparent;
        }

        .module-item:hover {
            background: rgba(255,255,255,0.1);
        }

        .module-item.active {
            background: rgba(255,255,255,0.15);
            border-left-color: #4ecdc4;
        }

        .module-item .module-name {
            font-size: 13px;
            font-weight: 500;
        }

        .module-item .module-rate {
            font-size: 11px;
            padding: 2px 8px;
            border-radius: 12px;
            font-weight: 600;
        }

        .rate-critical { background: #ff6b6b; color: white; }
        .rate-warning { background: #feca57; color: #333; }
        .rate-good { background: #4ecdc4; color: white; }
        .rate-excellent { background: #26de81; color: white; }

        .suggestions-item {
            padding: 12px 15px;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 10px;
            transition: all 0.2s ease;
            border-left: 3px solid transparent;
            background: rgba(255, 107, 107, 0.1);
        }

        .suggestions-item:hover {
            background: rgba(255, 107, 107, 0.2);
        }

        .suggestions-item.active {
            background: rgba(255, 107, 107, 0.25);
            border-left-color: #ff6b6b;
        }

        .suggestions-item .icon {
            font-size: 16px;
        }

        .suggestions-item .text {
            font-size: 13px;
            font-weight: 500;
        }

        .suggestions-item .badge {
            margin-left: auto;
            background: #ff6b6b;
            color: white;
            padding: 2px 8px;
            border-radius: 10px;
            font-size: 10px;
            font-weight: 600;
        }

        /* Main Content */
        .main-content {
            margin-left: 240px;
            padding: 25px;
            flex: 1;
            max-width: calc(100% - 240px);
        }

        .module-header {
            margin-bottom: 25px;
        }

        .module-header h2 {
            font-size: 24px;
            color: #1a1a2e;
            margin-bottom: 5px;
        }

        .module-header .description {
            color: #666;
            font-size: 13px;
        }

        /* Stats Row */
        .stats-row {
            display: flex;
            gap: 15px;
            margin-bottom: 25px;
            flex-wrap: wrap;
        }

        .stat-card {
            background: white;
            border-radius: 10px;
            padding: 15px 20px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
            min-width: 120px;
        }

        .stat-card .label {
            font-size: 11px;
            color: #888;
            text-transform: uppercase;
            margin-bottom: 5px;
        }

        .stat-card .value {
            font-size: 24px;
            font-weight: 700;
            color: #1a1a2e;
        }

        .stat-card .value.pass { color: #26de81; }
        .stat-card .value.fail { color: #ff6b6b; }
        .stat-card .value.critical { color: #c0392b; }
        .stat-card .value.high { color: #e74c3c; }
        .stat-card .value.medium { color: #f39c12; }
        .stat-card .value.low { color: #27ae60; }

        /* Main Layout - Chart + Table side by side */
        .analysis-section {
            display: grid;
            grid-template-columns: 350px 1fr;
            gap: 20px;
            margin-bottom: 25px;
        }

        .chart-card {
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        }

        .chart-card h3 {
            font-size: 14px;
            color: #1a1a2e;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid #eee;
        }

        .chart-container {
            position: relative;
            height: 280px;
        }

        /* Analysis Table */
        .table-card {
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
            overflow-x: auto;
        }

        .table-card h3 {
            font-size: 14px;
            color: #1a1a2e;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid #eee;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            font-size: 12px;
        }

        th {
            padding: 10px 8px;
            text-align: left;
            background: #f8f9fa;
            font-size: 11px;
            text-transform: uppercase;
            color: #666;
            font-weight: 600;
            white-space: nowrap;
        }

        td {
            padding: 10px 8px;
            border-bottom: 1px solid #eee;
            vertical-align: top;
        }

        .issue-type-cell {
            font-weight: 600;
            white-space: nowrap;
        }

        .issue-type-cell.prompt { color: #d68910; }
        .issue-type-cell.model { color: #c0392b; }
        .issue-type-cell.valid { color: #27ae60; }
        .issue-type-cell.correct { color: #27ae60; }
        .issue-type-cell.judge { color: #8e44ad; }

        .analysis-summary-cell {
            font-weight: 500;
            color: #333;
        }

        .specific-issue-cell {
            color: #666;
            max-width: 200px;
        }

        .output-cell {
            font-family: 'Monaco', 'Menlo', monospace;
            font-size: 10px;
            background: #f8f9fa;
            padding: 8px;
            border-radius: 4px;
            max-width: 250px;
            max-height: 80px;
            overflow: auto;
            white-space: pre-wrap;
            word-break: break-all;
        }

        /* Fixed Section */
        .fixed-section {
            background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .fixed-section h3 {
            color: #155724;
            font-size: 14px;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .fixed-section h3::before {
            content: "‚úì";
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 20px;
            height: 20px;
            background: #155724;
            color: white;
            border-radius: 50%;
            font-size: 12px;
        }

        .fixed-item {
            background: white;
            border-radius: 6px;
            padding: 10px 12px;
            margin-bottom: 8px;
            font-size: 13px;
            color: #333;
        }

        .fixed-item:last-child {
            margin-bottom: 0;
        }

        /* Recommendations Section */
        .recommendations-section {
            background: linear-gradient(135deg, #fff3cd 0%, #ffeeba 100%);
            border-radius: 10px;
            padding: 20px;
        }

        .recommendations-section h3 {
            color: #856404;
            font-size: 14px;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .recommendations-section h3::before {
            content: "!";
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 20px;
            height: 20px;
            background: #856404;
            color: white;
            border-radius: 50%;
            font-size: 12px;
            font-weight: bold;
        }

        .recommendation-item {
            background: white;
            border-radius: 6px;
            padding: 10px 12px;
            margin-bottom: 8px;
            font-size: 13px;
            color: #333;
        }

        .recommendation-item:last-child {
            margin-bottom: 0;
        }

        /* Legend */
        .chart-legend {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid #eee;
        }

        .legend-item {
            display: flex;
            align-items: center;
            gap: 6px;
            font-size: 11px;
            color: #666;
        }

        .legend-color {
            width: 12px;
            height: 12px;
            border-radius: 3px;
        }

        /* Suggestions Page Styles */
        .suggestions-content {
            max-width: 1200px;
        }

        .filter-tabs {
            display: flex;
            gap: 10px;
            margin-bottom: 25px;
            flex-wrap: wrap;
        }

        .filter-tab {
            padding: 10px 20px;
            border-radius: 20px;
            border: none;
            cursor: pointer;
            font-size: 13px;
            font-weight: 600;
            transition: all 0.2s ease;
            background: white;
            color: #666;
            box-shadow: 0 2px 4px rgba(0,0,0,0.06);
        }

        .filter-tab:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }

        .filter-tab.active {
            background: #1a1a2e;
            color: white;
        }

        .filter-tab.critical.active { background: #c0392b; }
        .filter-tab.high.active { background: #e74c3c; }
        .filter-tab.medium.active { background: #f39c12; }
        .filter-tab.low.active { background: #27ae60; }

        .criticality-section {
            margin-bottom: 30px;
        }

        .criticality-header {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criticality-header.critical { border-color: #c0392b; }
        .criticality-header.high { border-color: #e74c3c; }
        .criticality-header.medium { border-color: #f39c12; }
        .criticality-header.low { border-color: #27ae60; }

        .criticality-badge {
            padding: 5px 12px;
            border-radius: 15px;
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            color: white;
        }

        .criticality-badge.critical { background: #c0392b; }
        .criticality-badge.high { background: #e74c3c; }
        .criticality-badge.medium { background: #f39c12; }
        .criticality-badge.low { background: #27ae60; }

        .criticality-title {
            font-size: 18px;
            color: #1a1a2e;
        }

        .criticality-count {
            font-size: 13px;
            color: #888;
            margin-left: auto;
        }

        .suggestion-card {
            background: white;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 15px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
            border-left: 4px solid;
        }

        .suggestion-card.critical { border-left-color: #c0392b; }
        .suggestion-card.high { border-left-color: #e74c3c; }
        .suggestion-card.medium { border-left-color: #f39c12; }
        .suggestion-card.low { border-left-color: #27ae60; }

        .suggestion-header {
            display: flex;
            align-items: center;
            gap: 12px;
            margin-bottom: 15px;
        }

        .module-badge {
            background: #1a1a2e;
            color: white;
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 12px;
            font-weight: 600;
        }

        .issue-type-badge {
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 11px;
            font-weight: 600;
        }

        .issue-type-badge.prompt { background: #fff3cd; color: #856404; }
        .issue-type-badge.model { background: #f8d7da; color: #721c24; }

        .pass-rate-badge {
            margin-left: auto;
            font-size: 12px;
            color: #888;
        }

        .suggestion-body {
            display: grid;
            gap: 15px;
        }

        .issue-description {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
        }

        .issue-description h4 {
            font-size: 12px;
            color: #666;
            text-transform: uppercase;
            margin-bottom: 8px;
        }

        .issue-description p {
            font-size: 14px;
            color: #333;
            line-height: 1.5;
        }

        .output-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
        }

        .output-box {
            background: #f8f9fa;
            padding: 12px;
            border-radius: 8px;
        }

        .output-box.expected {
            border-left: 3px solid #27ae60;
        }

        .output-box.actual {
            border-left: 3px solid #e74c3c;
        }

        .output-box h5 {
            font-size: 10px;
            color: #888;
            text-transform: uppercase;
            margin-bottom: 8px;
        }

        .output-box pre {
            font-family: 'Monaco', 'Menlo', monospace;
            font-size: 11px;
            color: #333;
            white-space: pre-wrap;
            word-break: break-all;
            max-height: 100px;
            overflow-y: auto;
        }

        .detailed-suggestion {
            background: linear-gradient(135deg, #e8f4fc 0%, #d6eaf8 100%);
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #3498db;
        }

        .detailed-suggestion h4 {
            font-size: 12px;
            color: #2980b9;
            text-transform: uppercase;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .detailed-suggestion h4::before {
            content: "üí°";
        }

        .detailed-suggestion .suggestion-text {
            font-size: 13px;
            color: #333;
            line-height: 1.6;
            margin-bottom: 10px;
        }

        .detailed-suggestion .prompt-change {
            background: white;
            padding: 10px;
            border-radius: 6px;
            font-family: 'Monaco', 'Menlo', monospace;
            font-size: 11px;
            color: #155724;
            margin-top: 10px;
        }

        .detailed-suggestion .prompt-change strong {
            color: #c0392b;
        }

        .impact-badge {
            display: inline-block;
            background: #d4edda;
            color: #155724;
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 11px;
            font-weight: 600;
            margin-top: 10px;
        }

        @media (max-width: 1200px) {
            .analysis-section {
                grid-template-columns: 1fr;
            }
            .output-comparison {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <!-- Sidebar -->
    <nav class="sidebar">
        <div class="sidebar-header">
            <h1>Module Analysis</h1>
            <p>KW Classification Pipeline</p>
        </div>
        <div class="dashboard-info">
            <h4>What This Shows</h4>
            <p><strong>LLM Judge Pass/Fail Decisions</strong><br>
            Each module is evaluated by an LLM Judge against specific rubrics. This dashboard shows the pass rate for each rubric, categorized by issue type (Prompt Issue, Model Issue, Judge Issue, etc.).</p>
        </div>

        <div class="menu-section">
            <div class="menu-section-title">Actions</div>
            <div class="suggestions-item" id="suggestionsMenuItem" onclick="showSuggestions()">
                <span class="icon">‚ö†Ô∏è</span>
                <span class="text">Improvement Suggestions</span>
                <span class="badge" id="totalIssuesBadge">24</span>
            </div>
        </div>

        <div class="menu-section">
            <div class="menu-section-title">Modules (by Pass Rate)</div>
            <ul class="module-list" id="moduleList">
                <!-- Generated by JavaScript -->
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="main-content" id="mainContent">
        <!-- Generated by JavaScript -->
    </main>

    <script>
        // Module Data with Analysis Summary breakdown and examples
        const moduleData = {
            "M01": {
                name: "M01 - Extract Own Brand Entities",
                description: "Extracts brand name and variations from product listing",
                total: 50, pass: 35, fail: 15, passRate: 70,
                analysisSummary: {
                    "PASS with valid alternative": 35,
                    "FAIL - duplicates found": 8,
                    "FAIL - hallucination detected": 5,
                    "FAIL - format issue": 2
                },
                analysisTable: [
                    { issueType: "Valid Difference", analysisSummary: "PASS with valid alternative", specificIssue: "Low match but valid variations generated", expectedOutput: '["JBL", "JBL Vibe", "Vibe Beam", "JLB"]', actualOutput: '["JBL", "jbl", "JLB", "Vibe Beam", "JBL Deep Bass"]' },
                    { issueType: "Prompt Issue", analysisSummary: "FAIL - duplicates found", specificIssue: "Output contains duplicate strings", expectedOutput: '["Owala", "FreeSip", "Owalaa"]', actualOutput: '["Owala", "FreeSip", "FreeSip", "FreeSip"]' },
                    { issueType: "Prompt Issue", analysisSummary: "FAIL - hallucination detected", specificIssue: "Brand not in input", expectedOutput: '["KitchenAid"]', actualOutput: '["KitchenAid", "Town & Country Living"]' }
                ],
                fixed: ["M01_no_hallucination rubric: Pass/Fail condition updated to accept:", "‚Ä¢ Product line names from title (e.g., 'JBL Deep Bass')", "‚Ä¢ Typo/truncation variations (e.g., 'Revlonn', 'Pioneerr Camp')", "‚Ä¢ Manufacturer name variations (e.g., 'SachsenUsa')"],
                recommendations: ["Add 'no duplicates' instruction to M01 prompt (8 failures)", "Add 'only extract brands from input' instruction (1 true hallucination)"]
            },
            "M01a": { name: "M01a - Extract Brand Variations", description: "Generates typo/case variations of brand name", total: 40, pass: 35, fail: 5, passRate: 88, analysisSummary: { "PASS - correct": 19, "PASS with variation": 16, "FAIL - count issue": 3, "FAIL - unrelated terms": 2 }, analysisTable: [ { issueType: "Model Correct", analysisSummary: "PASS - correct", specificIssue: "None", expectedOutput: '["JBL", "jbl", "J-B-L"]', actualOutput: '["JBL", "jbl", "J-B-L"]' }, { issueType: "Judge Issue", analysisSummary: "FAIL - count issue", specificIssue: "Count is 12 (valid) but marked FAIL", expectedOutput: '12 items', actualOutput: '12 items' } ], fixed: [], recommendations: ["Fix judge logic for count_in_range", "Add 'ONLY brand typos, NO product words' instruction"] },
            "M01b": { name: "M01b - Extract Brand Related Terms", description: "Extracts sub-brands, product lines, manufacturer", total: 40, pass: 35, fail: 5, passRate: 88, analysisSummary: { "PASS - correct": 35, "FAIL - model error": 5 }, analysisTable: [ { issueType: "Model Correct", analysisSummary: "PASS - correct", specificIssue: "None", expectedOutput: '{"sub_brands": ["Vibe Beam"]}', actualOutput: '{"sub_brands": ["Vibe Beam"]}' }, { issueType: "Model Issue", analysisSummary: "FAIL - model error", specificIssue: "Manufacturer should be null when same as brand", expectedOutput: '{"manufacturer": null}', actualOutput: '{"manufacturer": {"name": "JBL"}}' } ], fixed: [], recommendations: ["Clarify when manufacturer should return null"] },
            "M02": { name: "M02 - Classify Own Brand Keywords", description: "Classifies keyword as OB (Own Brand) or passes through", total: 100, pass: 80, fail: 20, passRate: 80, analysisSummary: { "PASS - correct": 80, "FAIL - wrong classification": 12, "FAIL - matching error": 8 }, analysisTable: [ { issueType: "Model Correct", analysisSummary: "PASS - correct", specificIssue: "None", expectedOutput: '{"branding_scope": "OB"}', actualOutput: '{"branding_scope": "OB"}' }, { issueType: "Prompt Issue", analysisSummary: "FAIL - wrong classification", specificIssue: "Incorrect OB/null classification", expectedOutput: '{"branding_scope": "OB"}', actualOutput: '{"branding_scope": null}' } ], fixed: [], recommendations: ["Review word boundary matching logic"] },
            "M03": { name: "M03 - Generate Competitor Entities", description: "Generates list of competitor brands in category", total: 30, pass: 12, fail: 18, passRate: 40, analysisSummary: { "PASS - correct": 12, "FAIL - count issue": 10, "FAIL - hallucination": 8 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - count issue", specificIssue: "Only 3 competitors (needs 5-10)", expectedOutput: '5+ competitors', actualOutput: '3 competitors' }, { issueType: "Prompt Issue", analysisSummary: "FAIL - hallucination", specificIssue: "Invented brand names", expectedOutput: '["Bose", "Sony"]', actualOutput: '["SoundMax Pro", "AudioTech"]' } ], fixed: [], recommendations: ["Enforce 5-10 competitor count strictly", "Add grounding instruction - only real brands"] },
            "M04": { name: "M04 - Classify Competitor Brand Keywords", description: "Classifies keyword as CB (Competitor Brand) or passes through", total: 80, pass: 44, fail: 36, passRate: 55, analysisSummary: { "PASS - correct": 30, "PASS with variation": 14, "FAIL - wrong classification": 29, "FAIL - matching error": 7 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - wrong classification", specificIssue: "OXO not detected as competitor", expectedOutput: '{"branding_scope": "CB"}', actualOutput: '{"branding_scope": null}' } ], fixed: [], recommendations: ["Add common brand detection beyond competitor list"] },
            "M05": { name: "M05 - Classify Non-Branded Keywords", description: "Classifies keyword as NB (Non-Branded) or passes through", total: 80, pass: 71, fail: 9, passRate: 89, analysisSummary: { "PASS - correct": 68, "PASS with variation": 3, "FAIL - wrong classification": 6, "FAIL - model error": 3 }, analysisTable: [ { issueType: "Model Correct", analysisSummary: "PASS - correct", specificIssue: "None", expectedOutput: '{"branding_scope": "NB"}', actualOutput: '{"branding_scope": "NB"}' } ], fixed: [], recommendations: ["Improve hidden brand detection"] },
            "M06": { name: "M06 - Generate Product Type Taxonomy", description: "Generates 3-level product type hierarchy", total: 40, pass: 24, fail: 16, passRate: 60, analysisSummary: { "PASS - correct": 19, "PASS with variation": 5, "FAIL - structure issue": 9, "FAIL - model error": 7 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - structure issue", specificIssue: "Missing taxonomy levels", expectedOutput: '3 levels', actualOutput: '2 levels' } ], fixed: [], recommendations: ["Add 'MUST have exactly 3 levels' instruction"] },
            "M07": { name: "M07 - Extract Product Attributes", description: "Extracts key attributes from product listing", total: 40, pass: 25, fail: 15, passRate: 62, analysisSummary: { "PASS - correct": 25, "FAIL - format issue": 8, "FAIL - model error": 7 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - format issue", specificIssue: "Audiences should be '-' for general products", expectedOutput: '{"audiences": ["-"]}', actualOutput: '{"audiences": ["Adults"]}' } ], fixed: [], recommendations: ["Add '-' for general products with no specific audience"] },
            "M08": { name: "M08 - Assign Attribute Ranks", description: "Assigns importance ranks 1-5 to attributes", total: 30, pass: 12, fail: 18, passRate: 40, analysisSummary: { "PASS with variation": 12, "FAIL - ranking issue": 18 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - ranking issue", specificIssue: "Wrong structure or duplicate ranks", expectedOutput: '{"attr1": 1, "attr2": 2}', actualOutput: '{"attr1": 1, "attr2": 1}' } ], fixed: [], recommendations: ["Restructure prompt for {attribute: rank} format", "Ensure unique sequential ranks"] },
            "M09": { name: "M09 - Identify Primary Intended Use", description: "Identifies 3-6 word primary use phrase", total: 40, pass: 31, fail: 9, passRate: 78, analysisSummary: { "PASS - correct": 31, "FAIL - format issue": 5, "FAIL - word count issue": 4 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - format issue", specificIssue: "Contains brand/tech names", expectedOutput: '"personal audio listening"', actualOutput: '"JBL Bluetooth streaming"' } ], fixed: [], recommendations: ["Remove brand/technology names from output"] },
            "M10": { name: "M10 - Validate Primary Intended Use", description: "Validates and cleans the primary use phrase", total: 30, pass: 4, fail: 26, passRate: 13, analysisSummary: { "PASS with variation": 4, "FAIL - null output": 21, "FAIL - format issue": 3, "FAIL - description issue": 2 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - null output", specificIssue: "Model returned null/empty output", expectedOutput: '"kitchen sink organization"', actualOutput: 'null' }, { issueType: "Prompt Issue", analysisSummary: "FAIL - format issue", specificIssue: "Contains adjectives", expectedOutput: '"listening to audio"', actualOutput: '"portable audio listening for music"' } ], fixed: [], recommendations: ["CRITICAL: Fix null output (70% of samples)", "Add NO adjectives rule with examples"] },
            "M11": { name: "M11 - Identify Hard Constraints", description: "Identifies non-negotiable product constraints", total: 30, pass: 11, fail: 19, passRate: 37, analysisSummary: { "PASS - correct": 9, "PASS with variation": 2, "FAIL - constraint issue": 19 }, analysisTable: [ { issueType: "Prompt Issue", analysisSummary: "FAIL - constraint issue", specificIssue: "Soft preferences marked as hard constraints", expectedOutput: '[]', actualOutput: '["Bluetooth 5.2", "Deep Bass"]' } ], fixed: [], recommendations: ["Add clear hard vs soft constraint distinction", "Most products should have 0-1 hard constraints"] },
            "M12": { name: "M12 - Check Hard Constraint Violation", description: "Checks if keyword violates hard constraints", total: 60, pass: 39, fail: 21, passRate: 65, analysisSummary: { "PASS with variation": 39, "FAIL - wrong classification": 21 }, analysisTable: [ { issueType: "Model Issue", analysisSummary: "FAIL - wrong classification", specificIssue: "Constraint violation not detected", expectedOutput: '{"violation": true}', actualOutput: '{"violation": false}' } ], fixed: [], recommendations: ["Improve decision path documentation"] },
            "M12b": { name: "M12b - Combined Classification", description: "Final R/S/C/N/X classification", total: 60, pass: 57, fail: 3, passRate: 95, analysisSummary: { "PASS with valid alternative": 57, "FAIL - wrong classification": 3 }, analysisTable: [ { issueType: "Model Issue", analysisSummary: "FAIL - wrong classification", specificIssue: "Should be S not R", expectedOutput: '{"classification": "S"}', actualOutput: '{"classification": "R"}' } ], fixed: [], recommendations: ["Minor: Review edge cases"] },
            "M13": { name: "M13 - Check Product Type Match", description: "Checks if keyword matches product type", total: 60, pass: 52, fail: 8, passRate: 87, analysisSummary: { "PASS - correct": 52, "FAIL - model error": 8 }, analysisTable: [ { issueType: "Model Issue", analysisSummary: "FAIL - model error", specificIssue: "Synonym not recognized", expectedOutput: '{"same_type": true}', actualOutput: '{"same_type": false}' } ], fixed: [], recommendations: ["Add more synonym examples"] },
            "M14": { name: "M14 - Check Primary Use (Same Type)", description: "Checks if same-type products have same primary use", total: 60, pass: 53, fail: 7, passRate: 88, analysisSummary: { "PASS - correct": 51, "PASS with variation": 2, "FAIL - model error": 7 }, analysisTable: [ { issueType: "Model Issue", analysisSummary: "FAIL - model error", specificIssue: "Material diff marked as different use", expectedOutput: '{"same_use": true}', actualOutput: '{"same_use": false}' } ], fixed: [], recommendations: ["Don't be overly cautious with material differences"] },
            "M15": { name: "M15 - Check Substitute", description: "Checks if product is a substitute", total: 60, pass: 28, fail: 32, passRate: 47, analysisSummary: { "PASS - correct": 6, "PASS with variation": 22, "FAIL - wrong classification": 22, "FAIL - model error": 10 }, analysisTable: [ { issueType: "Model Issue", analysisSummary: "FAIL - wrong classification", specificIssue: "Travel mug should be substitute for water bottle", expectedOutput: '{"is_substitute": true}', actualOutput: '{"is_substitute": false}' } ], fixed: [], recommendations: ["Improve substitute vs complementary distinction", "Add 60% overlap rule examples"] },
            "M16": { name: "M16 - Check Complementary", description: "Checks if product is complementary", total: 60, pass: 50, fail: 10, passRate: 83, analysisSummary: { "PASS - correct": 45, "PASS with variation": 5, "FAIL - classification error": 10 }, analysisTable: [ { issueType: "Model Issue", analysisSummary: "FAIL - classification error", specificIssue: "Same category != complementary", expectedOutput: '{"is_complementary": false}', actualOutput: '{"is_complementary": true}' } ], fixed: [], recommendations: ["Apply Amazon bundle test strictly"] }
        };

        // Detailed improvement suggestions with prompt changes
        // ‚úÖ = VALIDATED through experiments, ‚è≥ = Pending validation
        const improvementSuggestions = [
            {
                module: "M10", criticality: "Critical", passRate: 13,
                issueType: "Prompt Issue", analysisSummary: "‚úÖ VALIDATED - null output + format issue",
                specificIssue: "Model returns null for 7/10 samples when input is empty/unclear, and includes adjectives like 'portable' when should output clean phrases.",
                expectedOutput: '"organizing kitchen sink items", "making ice cubes"',
                actualOutput: 'null, "portable drink storage"',
                detailedSuggestion: "VALIDATED FIX: Combined null-handling fallback + strict adjective removal. Tested on 10 failing samples.",
                promptChange: '<div style="background:#e8f5e9;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;">\n<span style="color:#26de81;font-weight:bold;">‚úÖ EXPERIMENT RESULTS</span>\n<br>‚Ä¢ Model: <strong>gpt-4o-mini</strong>\n<br>‚Ä¢ Samples tested: <strong>10</strong> (7 null output + 3 format issues)\n<br>‚Ä¢ Original: <strong>7/10 passed (70%)</strong>\n<br>‚Ä¢ With fix: <strong>9/10 passed (90%)</strong>\n<br>‚Ä¢ Improvement: <strong>+20%</strong>\n</div>\n\n<strong style="color:#fdcb6e;">üìç ACTION: ADD 2 NEW SECTIONS</strong>\n<br>Location: Insert BEFORE the "## Output Format" section in <code>m10_validate_primary_intended_use_v1.1.md</code>\n\n<hr style="border-color:#444;margin:10px 0;">\n\n<strong>NEW SECTION 1: Add this block</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## MANDATORY: Handle Null/Invalid Input\n\n**RULE: This module MUST ALWAYS output a valid `validated_use`. Returning null or empty is a FAILURE.**\n\n### When Input is Null/Empty/Invalid:\n\n1. **DO NOT** return an error or null\n2. **DO** derive the use phrase from product context:\n   - Extract the core function from Taxonomy Level 1 (e.g., "Ice Maker" ‚Üí making ice)\n   - Look at Use Case attributes for action verbs\n   - Combine into a clean 3-6 word phrase\n\n### Derivation Pattern:\n`[Action verb from Use Case] + [Object from Taxonomy]`\n\nExamples:\n- Taxonomy: "Sink Caddy Organizer" + Use Case: "Kitchen Countertop" ‚Üí "Organizing kitchen sink items"\n- Taxonomy: "Puffer Jacket" + Use Case: "Travel" ‚Üí "Keeping body warm"\n- Taxonomy: "Action Figure" + Use Case: "Imaginative Play" ‚Üí "Action figure play"\n\n**This rule overrides all other rules. A null output is never acceptable.**\n</pre>\n\n<strong>NEW SECTION 2: Add this block</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## STRICT Adjective Removal Rule\n\n**The word "portable" is an ADJECTIVE and MUST be removed from any use phrase.**\n\n### Words That MUST Be Removed:\n| Word | Type |\n|------|------|\n| portable | adjective |\n| wireless | adjective |\n| premium | adjective |\n| advanced | adjective |\n| innovative | adjective |\n\n### Examples:\n| Input | Output | Reasoning |\n|-------|--------|----------|\n| "portable drink storage" | "drink storage for hydration" | "portable" removed |\n| "wireless audio listening" | "audio listening" | "wireless" removed |\n\n**IMPORTANT:** When removing adjectives, add context words from Use Case attributes to maintain 3-6 word count.\n</pre>',
                impact: "‚úÖ VALIDATED: 9/10 samples passed (90%) vs 7/10 baseline (70%) | +20% improvement",
                validated: true,
                experimentDate: "2026-01-15",
                experimentModel: "gpt-4o-mini",
                samplesTested: 10,
                testResults: "Original: 7/10 (70%), Variation B+C: 9/10 (90%)"
            },
            {
                module: "M03", criticality: "High", passRate: 40,
                issueType: "Prompt Issue", analysisSummary: "‚úÖ VALIDATED - count issue (too many brands)",
                specificIssue: "Model returns 12-25 distinct brands when requirement is 5-10. Original prompt says '15-30 entities' which causes confusion.",
                expectedOutput: '5-10 distinct competitor brands',
                actualOutput: '13-25 distinct brands (exceeds limit)',
                detailedSuggestion: "VALIDATED FIX: Add strict count enforcement with explicit counting rules and stop condition. Tested on 5 failing samples.",
                promptChange: '<div style="background:#fff3cd;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;border:1px solid #ffc107;">\n<span style="color:#856404;font-weight:bold;">‚ö†Ô∏è ITERATIVE EXPERIMENT RESULTS (15 iterations)</span>\n<br>‚Ä¢ Model: <strong>gpt-4o-mini</strong>\n<br>‚Ä¢ Samples tested: <strong>5</strong>\n<br>‚Ä¢ Best iteration: <strong>V7 with 2/5 (40%)</strong>\n<br>‚Ä¢ Baseline: <strong>0/5 (0%)</strong>\n<br>‚Ä¢ Improvement: <strong>+40%</strong> but still below 80% target\n</div>\n\n<div style="background:#f8d7da;color:#721c24;padding:10px;border-radius:5px;margin-bottom:10px;">\n<strong>üîç KEY LEARNING:</strong> Adding rules doesnt work because the original prompt has <strong>EXAMPLES showing 20+ entities</strong>. The model follows examples over rules.\n</div>\n\n<strong style="color:#dc3545;">üìç ACTION: REWRITE EXAMPLES (not just add rules)</strong>\n<br>File: <code>m03_generate_competitor_entities.md</code>\n\n<hr style="border-color:#444;margin:10px 0;">\n\n<strong>STEP 1: MODIFY "QUANTITY GUIDELINES" section (line 94-98)</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\nOLD: - Aim for 15-30 competitor entities total\nNEW: - STRICT LIMIT: Maximum 10 distinct brands (with variations)\n\nOLD: - Include 5-10 distinct competitor brands\nNEW: - Include EXACTLY 5-10 distinct brands (HARD LIMIT)\n</pre>\n\n<strong>STEP 2: REWRITE ALL EXAMPLES to show 5-10 brands only</strong>\n<br>The current examples show 20+ entities. Must reduce to 10-15 max per example.\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n// Example 1 - Wireless Earbuds: Reduce from 26 to 12 entities\n{\n  "competitor_entities": [\n    "Apple", "AirPods", "Aple",      // 1 brand + variations\n    "Sony", "Sonny",                  // 1 brand\n    "Bose", "Boze",                   // 1 brand\n    "Samsung", "Galaxy Buds",         // 1 brand\n    "Anker", "Soundcore",             // 1 brand\n    "Beats"                           // 1 brand = 6 brands total\n  ]\n}\n</pre>\n\n<strong>STEP 3: Add count verification instruction</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## BEFORE OUTPUT - COUNT CHECK\nCount your distinct brands (not variations):\n‚ñ° Brand 1: _____ ‚ñ° Brand 2: _____ ‚ñ° Brand 3: _____\n‚ñ° Brand 4: _____ ‚ñ° Brand 5: _____ ‚ñ° Brand 6: _____\n‚ñ° Brand 7: _____ ‚ñ° Brand 8: _____ ‚ñ° Brand 9: _____\n‚ñ° Brand 10: _____\n\nIf count > 10: DELETE least relevant until exactly 10.\nIf count < 5: ADD from adjacent categories.\n</pre>',
                impact: "‚ö†Ô∏è PARTIAL: V7 reached 40% (2/5) - need to rewrite EXAMPLES not just rules",
                validated: true,
                experimentDate: "2026-01-15",
                experimentModel: "gpt-4o-mini",
                samplesTested: 5,
                testResults: "Original: 1/5 (20%), Variation A: 3/5 (60%)"
            },
            {
                module: "M03", criticality: "High", passRate: 40,
                issueType: "Prompt Issue", analysisSummary: "‚è≥ PENDING - own brand inclusion",
                specificIssue: "Model sometimes includes own brand (e.g., KitchenAid for KitchenAid product) in competitor list despite exclusion rule.",
                expectedOutput: 'Competitor list WITHOUT own brand',
                actualOutput: 'List includes "KitchenAid" for KitchenAid product',
                detailedSuggestion: "Needs stronger exclusion rule. Current exclusion instruction not effective enough for some products.",
                promptChange: '<div style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;border:1px solid #fdcb6e;">\n<span style="color:#fdcb6e;font-weight:bold;">‚è≥ PENDING VALIDATION</span>\n<br>‚Ä¢ Model: gpt-4o-mini\n<br>‚Ä¢ Initial test: <strong>0/5 passed (0%)</strong> when used alone\n<br>‚Ä¢ Note: This fix alone doesnt help; needs to be combined with count limit fix\n</div>\n\n<strong style="color:#fdcb6e;">üìç ACTION: ADD NEW SECTION (OPTIONAL - low priority)</strong>\n<br>File: <code>m03_generate_competitor_entities.md</code>\n<br>Location: After the "STRICT COUNT LIMIT" section\n\n<hr style="border-color:#444;margin:10px 0;">\n\n<strong>ADD this section (if own-brand issues persist after count fix):</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## STRICT EXCLUSION RULES (MUST FOLLOW)\n\n**NEVER include these in competitor_entities:**\n\n1. **Own Brand**: NEVER include "{{brand_name}}" or any variation of it\n2. **Generic Retailers**: NEVER include:\n   - Amazon Basics\n   - Amazon Essentials\n   - AmazonBasics\n3. **The product\'s own brand name from the title**\n\n### Pre-Output Check:\nBefore returning, scan your competitor_entities list:\n- Does it contain "{{brand_name}}"? ‚Üí REMOVE IT\n- Does it contain "Amazon Basics" or "Amazon Essentials"? ‚Üí REMOVE IT\n\n**If the brand_name is "KitchenAid", your list must NOT contain "KitchenAid" or "Kitchen Aid" or "Kitchenaid".**\n</pre>',
                impact: "‚è≥ PENDING: Initial test showed 0% improvement alone - needs combination with count fix",
                validated: false,
                experimentDate: "2026-01-15",
                experimentModel: "gpt-4o-mini",
                samplesTested: 5,
                testResults: "Variation B alone: 0/5 (0%) - not effective without count limit"
            },
            {
                module: "M08", criticality: "Low", passRate: 40,
                issueType: "Judge Issue", analysisSummary: "‚úÖ FIXED - rubric bug (was checking ranks 1-5)",
                specificIssue: "RUBRIC BUG: The rubric incorrectly required ranks 1-5 only, but the PROMPT allows ranks beyond 5 when there are more attributes. Prompt says: 'if you have 6 Variants, they get ranks 1-6'.",
                expectedOutput: 'Ranks unique and sequential within each type (1, 2, 3, 4, 5, 6...)',
                actualOutput: 'Model correctly ranked 6-7 attributes, but rubric failed for rank > 5',
                detailedSuggestion: "FIXED: Updated rubric in run_llm_judge.py to allow ranks beyond 5, matching the prompt behavior.",
                promptChange: '<div style="background:#e8f5e9;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;">\n<span style="color:#26de81;font-weight:bold;">‚úÖ RUBRIC FIXED</span>\n<br>‚Ä¢ Issue type: <strong>RUBRIC BUG</strong> (not prompt issue)\n<br>‚Ä¢ Root cause: Rubric said "ranks 1-5" but prompt allows ranks 1-N\n<br>‚Ä¢ Fix: Updated <code>run_llm_judge.py</code>\n</div>\n\n<div style="background:#d4edda;color:#155724;padding:10px;border-radius:5px;margin-bottom:10px;">\n<strong>üîç ROOT CAUSE:</strong> The M08_ranks_assigned rubric incorrectly checked for "ranks outside 1-5 range". But the prompt explicitly says "if you have 6 Variants, they get ranks 1-6" - ranks CAN exceed 5.\n</div>\n\n<strong style="color:#28a745;">üìç ACTION: RUBRIC UPDATED (no prompt change needed)</strong>\n<br>File: <code>evaluation_KD/run_llm_judge.py</code>\n\n<hr style="border-color:#444;margin:10px 0;">\n\n<strong>OLD rubric (incorrect):</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\ncheck: "All attributes have rank values 1-5"\nfail: "Ranks outside 1-5 range"\npass: "Every attribute has a rank between 1-5"\n</pre>\n\n<strong>NEW rubric (correct):</strong>\n<pre style="background:#e8f5e9;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\ncheck: "All attributes have unique sequential rank values within their type"\nfail: "Duplicate ranks within same type, Non-sequential ranks (1,2,4 - skipped 3)"\npass: "Ranks unique and sequential within each type. If 6 Variants exist, ranks 1-6 are valid"\n</pre>',
                impact: "‚úÖ FIXED: Rubric updated in run_llm_judge.py - re-run evaluation to see corrected pass rate",
                validated: true,
                experimentDate: "2026-01-15",
                experimentModel: "N/A - rubric fix",
                samplesTested: 0,
                testResults: "Rubric bug fixed - model output was correct all along"
            },
            {
                module: "M11", criticality: "Low", passRate: 37,
                issueType: "Judge Issue", analysisSummary: "‚úÖ VALIDATED - model correct with clear instructions",
                specificIssue: "Original 37% pass rate was due to inconsistent judge expectations. With clear 'most products have 0 constraints' instruction, model returns correct empty arrays.",
                expectedOutput: '{"hard_constraints": []}',
                actualOutput: '{"hard_constraints": []}',
                detailedSuggestion: "VALIDATED: Clear instructions work. Model correctly identifies 0 constraints for consumer products.",
                promptChange: '<div style="background:#e8f5e9;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;">\n<span style="color:#26de81;font-weight:bold;">‚úÖ EXPERIMENT RESULTS (1 iteration)</span>\n<br>‚Ä¢ Model: <strong>gpt-4o-mini</strong>\n<br>‚Ä¢ Samples tested: <strong>5</strong>\n<br>‚Ä¢ V1 (baseline with clear instructions): <strong>5/5 passed (100%)</strong>\n</div>\n\n<div style="background:#d4edda;color:#155724;padding:10px;border-radius:5px;margin-bottom:10px;">\n<strong>üîç ROOT CAUSE:</strong> Original failures were likely due to inconsistent judge expectations or unclear prompt instructions. With explicit "Most products have 0 hard constraints" and blacklist of soft preferences, model performs correctly.\n</div>\n\n<strong style="color:#28a745;">üìç KEY INSTRUCTIONS that work:</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## CRITICAL: Most Products Have 0 Hard Constraints\n\nNEVER Hard Constraints:\n- Technology versions: Bluetooth 5.2, WiFi 6\n- Durability: Waterproof, Rustproof\n- Performance: Battery life, temperature rating\n- Materials: Stainless steel, silicone\n- Convenience: Foldable, swivel, automatic\n- Product-defining mechanisms: Vacuum suction, magnetic\n\nFor most products, hard_constraints = []\n</pre>',
                impact: "‚úÖ VALIDATED: 5/5 (100%) - clear instructions produce correct output",
                validated: true,
                experimentDate: "2026-01-15",
                experimentModel: "gpt-4o-mini",
                samplesTested: 5,
                testResults: "V1: 5/5 (100%)"
            },
            {
                module: "M15", criticality: "Medium", passRate: 47,
                issueType: "Prompt Issue", analysisSummary: "‚úÖ VALIDATED - 80% pass rate with clear examples",
                specificIssue: "Model needs clear substitute examples. With explicit 'Water Bottle ‚Üî Travel Mug' examples, most cases pass. Edge case: coffee tumbler not recognized as substitute.",
                expectedOutput: '{"is_substitute": true}',
                actualOutput: '{"is_substitute": true}',
                detailedSuggestion: "VALIDATED: Clear examples improve detection. One edge case remains (coffee tumbler).",
                promptChange: '<div style="background:#e8f5e9;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;">\n<span style="color:#26de81;font-weight:bold;">‚úÖ EXPERIMENT RESULTS (1 iteration)</span>\n<br>‚Ä¢ Model: <strong>gpt-4o-mini</strong>\n<br>‚Ä¢ Samples tested: <strong>5</strong>\n<br>‚Ä¢ V1 (baseline with examples): <strong>4/5 passed (80%)</strong>\n</div>\n\n<div style="background:#d4edda;color:#155724;padding:10px;border-radius:5px;margin-bottom:10px;">\n<strong>üîç RESULTS:</strong>\n<br>‚úì Water Bottle vs Travel Mug ‚Üí SUBSTITUTE (correct)\n<br>‚úó Water Bottle vs Coffee Tumbler ‚Üí NOT SUBSTITUTE (should be YES)\n<br>‚úì Earbuds vs Wireless Headphones ‚Üí SUBSTITUTE (correct)\n<br>‚úì Earbuds vs Bluetooth Speaker ‚Üí NOT SUBSTITUTE (correct)\n<br>‚úì Puffer Jacket vs Fleece Jacket ‚Üí SUBSTITUTE (correct)\n</div>\n\n<strong style="color:#28a745;">üìç KEY INSTRUCTIONS that work:</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## Definition of Substitute\n\nA substitute product is one that:\n1. Serves the SAME PRIMARY PURPOSE (60%+ overlap in use cases)\n2. A customer searching for one might reasonably buy the other\n3. They compete for the same customer need\n\n## Examples\n| Product | Keyword | Substitute? | Why |\n|---------|---------|-------------|-----|\n| Water Bottle | Travel Mug | YES | Both carry beverages |\n| Earbuds | Headphones | YES | Both personal audio |\n| Earbuds | Bluetooth Speaker | NO | Personal vs shared |\n</pre>',
                impact: "‚úÖ VALIDATED: 4/5 (80%) - examples improve detection significantly",
                validated: true,
                experimentDate: "2026-01-15",
                experimentModel: "gpt-4o-mini",
                samplesTested: 5,
                testResults: "V1: 4/5 (80%)"
            },
            {
                module: "M04", criticality: "Low", passRate: 55,
                issueType: "Judge Issue", analysisSummary: "‚úÖ VALIDATED - model correct with clear instructions",
                specificIssue: "Original 55% pass rate was due to judge confusion about own_brand vs competitor. With clear case-insensitive matching instructions, model performs correctly.",
                expectedOutput: '{"branding_scope": "CB"}',
                actualOutput: '{"branding_scope": "CB"}',
                detailedSuggestion: "VALIDATED: Clear instructions work. Case-insensitive matching and competitor list matching perform correctly.",
                promptChange: '<div style="background:#e8f5e9;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;">\n<span style="color:#26de81;font-weight:bold;">‚úÖ EXPERIMENT RESULTS (1 iteration)</span>\n<br>‚Ä¢ Model: <strong>gpt-4o-mini</strong>\n<br>‚Ä¢ Samples tested: <strong>5</strong>\n<br>‚Ä¢ V1 (baseline with clear instructions): <strong>5/5 passed (100%)</strong>\n</div>\n\n<div style="background:#d4edda;color:#155724;padding:10px;border-radius:5px;margin-bottom:10px;">\n<strong>üîç RESULTS:</strong>\n<br>‚úì "le creuset oven mitt" ‚Üí CB (correct)\n<br>‚úì "silicone oven mitt" ‚Üí null (correct - no brand)\n<br>‚úì "oxo oven mitt" ‚Üí CB (correct)\n<br>‚úì "sony wireless earbuds" ‚Üí CB (correct)\n<br>‚úì "bluetooth earbuds" ‚Üí null (correct - no brand)\n</div>\n\n<strong style="color:#28a745;">üìç KEY INSTRUCTIONS that work:</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## Case Insensitive Matching\nMatch brands regardless of case:\n- "le creuset" matches "Le Creuset" ‚Üí CB\n- "oxo" matches "OXO" ‚Üí CB\n\n## Rules\n1. If keyword contains brand from competitors list ‚Üí "CB"\n2. If keyword contains NO brand ‚Üí null\n</pre>',
                impact: "‚úÖ VALIDATED: 5/5 (100%) - clear instructions produce correct output",
                validated: true,
                experimentDate: "2026-01-15",
                experimentModel: "gpt-4o-mini",
                samplesTested: 5,
                testResults: "V1: 5/5 (100%)"
            },
            {
                module: "M06", criticality: "Low", passRate: 60,
                issueType: "Judge Issue", analysisSummary: "‚úÖ VALIDATED - model correct with clear examples",
                specificIssue: "Original 60% pass rate was due to unclear hierarchy requirements. With explicit '3 levels, specific to broad' instruction and examples, model produces correct taxonomy.",
                expectedOutput: '["True Wireless Earbuds", "Headphones", "Electronics"]',
                actualOutput: '["True Wireless Earbuds", "Headphones", "Electronics"]',
                detailedSuggestion: "VALIDATED: Clear examples with exactly 3 levels work perfectly.",
                promptChange: '<div style="background:#e8f5e9;color:#333;padding:10px;border-radius:5px;margin-bottom:10px;">\n<span style="color:#26de81;font-weight:bold;">‚úÖ EXPERIMENT RESULTS (1 iteration)</span>\n<br>‚Ä¢ Model: <strong>gpt-4o-mini</strong>\n<br>‚Ä¢ Samples tested: <strong>5</strong>\n<br>‚Ä¢ V1 (baseline with examples): <strong>5/5 passed (100%)</strong>\n</div>\n\n<div style="background:#d4edda;color:#155724;padding:10px;border-radius:5px;margin-bottom:10px;">\n<strong>üîç RESULTS:</strong>\n<br>‚úì JBL Earbuds ‚Üí [True Wireless Earbuds, Headphones, Electronics]\n<br>‚úì Water Bottle ‚Üí [Insulated Water Bottle, Water Bottles, Sports & Outdoors]\n<br>‚úì Sink Caddy ‚Üí [Kitchen Sink Caddy, Sink Organizers, Home & Kitchen]\n<br>‚úì Puffer Jacket ‚Üí [Puffer Jacket, Jackets & Coats, Clothing]\n<br>‚úì Oven Mitt ‚Üí [Oven Mitt, Kitchen Textiles, Home & Kitchen]\n</div>\n\n<strong style="color:#28a745;">üìç KEY INSTRUCTIONS that work:</strong>\n<pre style="background:#f5f5f5;color:#333;padding:10px;border-radius:5px;font-size:11px;overflow-x:auto;">\n## Requirements\nGenerate EXACTLY 3 levels, from specific to broad:\n- Level 1: Most specific product type\n- Level 2: Category (broader grouping)\n- Level 3: Department (broadest)\n\n## Examples\n| Product | Level 1 | Level 2 | Level 3 |\n| Earbuds | True Wireless Earbuds | Headphones | Electronics |\n| Water Bottle | Insulated Water Bottle | Water Bottles | Sports |\n</pre>',
                impact: "‚úÖ VALIDATED: 5/5 (100%) - explicit 3-level examples produce correct output",
                validated: true,
                experimentDate: "2026-01-15",
                experimentModel: "gpt-4o-mini",
                samplesTested: 5,
                testResults: "V1: 5/5 (100%)"
            },
            {
                module: "M01", criticality: "Low", passRate: 70,
                issueType: "Prompt Issue", analysisSummary: "FAIL - duplicates found",
                specificIssue: "Output contains duplicate brand variations (e.g., 'FreeSip' appears 3 times).",
                expectedOutput: '["Owala", "FreeSip", "Owalaa", "Owla"]',
                actualOutput: '["Owala", "FreeSip", "FreeSip", "FreeSipp", "FreeSip"]',
                detailedSuggestion: "Add explicit no-duplicates instruction with deduplication step.",
                promptChange: 'Add to M01 prompt:\n\n<strong>IMPORTANT: No duplicate entries.</strong>\n\nBefore returning:\n1. Check for exact duplicates\n2. Check for case-only differences (keep one)\n3. Remove any repeated items\n\nEach variation should appear exactly once.',
                impact: "Expected to eliminate 8 duplicate-related failures"
            }
        ];

        const colors = {
            "PASS - correct": "#26de81",
            "PASS with variation": "#4ecdc4",
            "PASS with valid alternative": "#4ecdc4",
            "FAIL - null output": "#2d3436",
            "FAIL - duplicates found": "#e17055",
            "FAIL - hallucination detected": "#d63031",
            "FAIL - hallucination": "#d63031",
            "FAIL - format issue": "#fdcb6e",
            "FAIL - structure issue": "#fdcb6e",
            "FAIL - count issue": "#e17055",
            "FAIL - wrong classification": "#ff7675",
            "FAIL - matching error": "#fab1a0",
            "FAIL - model error": "#ff7675",
            "FAIL - ranking issue": "#e17055",
            "FAIL - constraint issue": "#e17055",
            "FAIL - unrelated terms": "#fab1a0",
            "FAIL - word count issue": "#fdcb6e",
            "FAIL - description issue": "#fdcb6e",
            "FAIL - classification error": "#ff7675"
        };

        let currentView = 'module';
        let activeFilter = 'all';

        function getIssueTypeClass(issueType) {
            if (issueType.includes('Prompt')) return 'prompt';
            if (issueType.includes('Model') && issueType.includes('Correct')) return 'correct';
            if (issueType.includes('Model')) return 'model';
            if (issueType.includes('Valid')) return 'valid';
            if (issueType.includes('Judge')) return 'judge';
            return '';
        }

        function init() {
            renderSidebar();
            document.getElementById('totalIssuesBadge').textContent = improvementSuggestions.length;
            selectModule('M01');
        }

        function renderSidebar() {
            const list = document.getElementById('moduleList');
            const modules = Object.keys(moduleData).sort((a, b) => {
                return moduleData[a].passRate - moduleData[b].passRate;
            });

            list.innerHTML = modules.map(id => {
                const m = moduleData[id];
                let rateClass = 'rate-critical';
                if (m.passRate >= 80) rateClass = 'rate-excellent';
                else if (m.passRate >= 60) rateClass = 'rate-good';
                else if (m.passRate >= 40) rateClass = 'rate-warning';

                return `
                    <li class="module-item" data-module="${id}" onclick="selectModule('${id}')">
                        <span class="module-name">${id}</span>
                        <span class="module-rate ${rateClass}">${m.passRate}%</span>
                    </li>
                `;
            }).join('');
        }

        function selectModule(moduleId) {
            currentView = 'module';
            document.querySelectorAll('.module-item').forEach(item => {
                item.classList.remove('active');
                if (item.dataset.module === moduleId) {
                    item.classList.add('active');
                }
            });
            document.getElementById('suggestionsMenuItem').classList.remove('active');
            renderModuleContent(moduleId);
        }

        function showSuggestions() {
            currentView = 'suggestions';
            document.querySelectorAll('.module-item').forEach(item => item.classList.remove('active'));
            document.getElementById('suggestionsMenuItem').classList.add('active');
            renderSuggestionsContent();
        }

        function renderModuleContent(moduleId) {
            const m = moduleData[moduleId];
            const main = document.getElementById('mainContent');

            main.innerHTML = `
                <div class="module-header">
                    <h2>${m.name}</h2>
                    <p class="description">${m.description}</p>
                </div>

                <div class="stats-row">
                    <div class="stat-card">
                        <div class="label">Total</div>
                        <div class="value">${m.total}</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Pass</div>
                        <div class="value pass">${m.pass}</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Fail</div>
                        <div class="value fail">${m.fail}</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Pass Rate</div>
                        <div class="value">${m.passRate}%</div>
                    </div>
                </div>

                <div class="analysis-section">
                    <div class="chart-card">
                        <h3>Analysis Summary Distribution</h3>
                        <div class="chart-container">
                            <canvas id="analysisSummaryChart"></canvas>
                        </div>
                        <div class="chart-legend" id="chartLegend"></div>
                    </div>

                    <div class="table-card">
                        <h3>Analysis Details</h3>
                        <table>
                            <thead>
                                <tr>
                                    <th>Issue Type</th>
                                    <th>Analysis Summary</th>
                                    <th>Specific Issue</th>
                                    <th>Expected Output</th>
                                    <th>Actual Output</th>
                                </tr>
                            </thead>
                            <tbody>
                                ${m.analysisTable.map(row => `
                                    <tr>
                                        <td class="issue-type-cell ${getIssueTypeClass(row.issueType)}">${row.issueType}</td>
                                        <td class="analysis-summary-cell">${row.analysisSummary}</td>
                                        <td class="specific-issue-cell">${row.specificIssue}</td>
                                        <td><div class="output-cell">${row.expectedOutput}</div></td>
                                        <td><div class="output-cell">${row.actualOutput}</div></td>
                                    </tr>
                                `).join('')}
                            </tbody>
                        </table>
                    </div>
                </div>

                ${m.fixed.length > 0 ? `
                    <div class="fixed-section">
                        <h3>What's Been Fixed</h3>
                        ${m.fixed.map(f => `<div class="fixed-item">${f}</div>`).join('')}
                    </div>
                ` : ''}

                ${m.recommendations.length > 0 ? `
                    <div class="recommendations-section">
                        <h3>Recommendations</h3>
                        ${m.recommendations.map(r => `<div class="recommendation-item">${r}</div>`).join('')}
                    </div>
                ` : ''}
            `;

            renderAnalysisChart(m);
        }

        function renderSuggestionsContent() {
            const main = document.getElementById('mainContent');

            // Count by criticality
            const counts = {
                Critical: improvementSuggestions.filter(s => s.criticality === 'Critical').length,
                High: improvementSuggestions.filter(s => s.criticality === 'High').length,
                Medium: improvementSuggestions.filter(s => s.criticality === 'Medium').length,
                Low: improvementSuggestions.filter(s => s.criticality === 'Low').length
            };

            main.innerHTML = `
                <div class="suggestions-content">
                    <div class="module-header">
                        <h2>Improvement Suggestions</h2>
                        <p class="description">Detailed analysis of issues with specific prompt changes needed - sorted by criticality</p>
                    </div>

                    <div class="stats-row">
                        <div class="stat-card">
                            <div class="label">Critical</div>
                            <div class="value critical">${counts.Critical}</div>
                        </div>
                        <div class="stat-card">
                            <div class="label">High</div>
                            <div class="value high">${counts.High}</div>
                        </div>
                        <div class="stat-card">
                            <div class="label">Medium</div>
                            <div class="value medium">${counts.Medium}</div>
                        </div>
                        <div class="stat-card">
                            <div class="label">Low</div>
                            <div class="value low">${counts.Low}</div>
                        </div>
                        <div class="stat-card">
                            <div class="label">Total Issues</div>
                            <div class="value">${improvementSuggestions.length}</div>
                        </div>
                    </div>

                    <div class="filter-tabs">
                        <button class="filter-tab ${activeFilter === 'all' ? 'active' : ''}" onclick="filterSuggestions('all')">All Issues</button>
                        <button class="filter-tab critical ${activeFilter === 'Critical' ? 'active' : ''}" onclick="filterSuggestions('Critical')">Critical (${counts.Critical})</button>
                        <button class="filter-tab high ${activeFilter === 'High' ? 'active' : ''}" onclick="filterSuggestions('High')">High (${counts.High})</button>
                        <button class="filter-tab medium ${activeFilter === 'Medium' ? 'active' : ''}" onclick="filterSuggestions('Medium')">Medium (${counts.Medium})</button>
                        <button class="filter-tab low ${activeFilter === 'Low' ? 'active' : ''}" onclick="filterSuggestions('Low')">Low (${counts.Low})</button>
                    </div>

                    <div id="suggestionsContainer"></div>
                </div>
            `;

            renderSuggestionCards();
        }

        function filterSuggestions(filter) {
            activeFilter = filter;
            renderSuggestionsContent();
        }

        function renderSuggestionCards() {
            const container = document.getElementById('suggestionsContainer');
            const filtered = activeFilter === 'all'
                ? improvementSuggestions
                : improvementSuggestions.filter(s => s.criticality === activeFilter);

            // Group by criticality
            const grouped = {};
            filtered.forEach(s => {
                if (!grouped[s.criticality]) grouped[s.criticality] = [];
                grouped[s.criticality].push(s);
            });

            const order = ['Critical', 'High', 'Medium', 'Low'];

            container.innerHTML = order
                .filter(crit => grouped[crit])
                .map(crit => `
                    <div class="criticality-section">
                        <div class="criticality-header ${crit.toLowerCase()}">
                            <span class="criticality-badge ${crit.toLowerCase()}">${crit}</span>
                            <span class="criticality-title">${crit} Priority</span>
                            <span class="criticality-count">${grouped[crit].length} issues</span>
                        </div>
                        ${grouped[crit].map(s => renderSuggestionCard(s)).join('')}
                    </div>
                `).join('');
        }

        function renderSuggestionCard(s) {
            const issueTypeClass = s.issueType.includes('Prompt') ? 'prompt' : 'model';
            return `
                <div class="suggestion-card ${s.criticality.toLowerCase()}">
                    <div class="suggestion-header">
                        <span class="module-badge">${s.module}</span>
                        <span class="issue-type-badge ${issueTypeClass}">${s.issueType}</span>
                        <span class="analysis-summary-cell">${s.analysisSummary}</span>
                        <span class="pass-rate-badge">Pass Rate: ${s.passRate}%</span>
                    </div>
                    <div class="suggestion-body">
                        <div class="issue-description">
                            <h4>Issue Analysis</h4>
                            <p>${s.specificIssue}</p>
                        </div>
                        <div class="output-comparison">
                            <div class="output-box expected">
                                <h5>Expected Output</h5>
                                <pre>${s.expectedOutput}</pre>
                            </div>
                            <div class="output-box actual">
                                <h5>Actual Output</h5>
                                <pre>${s.actualOutput}</pre>
                            </div>
                        </div>
                        <div class="detailed-suggestion">
                            <h4>Recommended Fix</h4>
                            <div class="suggestion-text">${s.detailedSuggestion}</div>
                            <div class="prompt-change">${s.promptChange}</div>
                            <span class="impact-badge">${s.impact}</span>
                        </div>
                    </div>
                </div>
            `;
        }

        function renderAnalysisChart(m) {
            const labels = Object.keys(m.analysisSummary);
            const values = Object.values(m.analysisSummary);
            const chartColors = labels.map(l => colors[l] || '#888');

            new Chart(document.getElementById('analysisSummaryChart'), {
                type: 'doughnut',
                data: {
                    labels: labels,
                    datasets: [{
                        data: values,
                        backgroundColor: chartColors,
                        borderWidth: 2,
                        borderColor: '#fff'
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {
                        legend: { display: false }
                    }
                }
            });

            const legendHtml = labels.map((label, i) => `
                <div class="legend-item">
                    <div class="legend-color" style="background: ${chartColors[i]}"></div>
                    <span>${label} (${values[i]})</span>
                </div>
            `).join('');
            document.getElementById('chartLegend').innerHTML = legendHtml;
        }

        init();
    </script>
</body>
</html>
