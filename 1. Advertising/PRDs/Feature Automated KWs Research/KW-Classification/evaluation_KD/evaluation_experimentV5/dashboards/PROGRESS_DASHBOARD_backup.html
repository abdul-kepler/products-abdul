<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prompt Version Progress Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {
            --bg-primary: #0f172a;
            --bg-secondary: #1e293b;
            --bg-card: #1e293b;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
            --accent-blue: #3b82f6;
            --accent-green: #22c55e;
            --accent-yellow: #eab308;
            --accent-red: #ef4444;
            --accent-purple: #a855f7;
            --border-color: #334155;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            min-height: 100vh;
            padding: 20px;
        }

        .container { max-width: 1400px; margin: 0 auto; }

        header {
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 1px solid var(--border-color);
        }

        header h1 {
            font-size: 2rem;
            margin-bottom: 8px;
            background: linear-gradient(135deg, var(--accent-blue), var(--accent-purple));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        header p { color: var(--text-secondary); }

        .module-selector {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        .module-btn {
            padding: 10px 20px;
            border: 1px solid var(--border-color);
            background: var(--bg-secondary);
            color: var(--text-primary);
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.2s;
            font-size: 14px;
        }

        .module-btn:hover { border-color: var(--accent-blue); }
        .module-btn.active { background: var(--accent-blue); border-color: var(--accent-blue); }

        .dashboard-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 30px;
        }

        @media (max-width: 1000px) { .dashboard-grid { grid-template-columns: 1fr; } }

        .card {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 20px;
            border: 1px solid var(--border-color);
        }

        .card h2 {
            font-size: 1.1rem;
            margin-bottom: 15px;
            color: var(--text-secondary);
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .card h2::before {
            content: '';
            width: 4px;
            height: 20px;
            background: var(--accent-blue);
            border-radius: 2px;
        }

        .chart-container { position: relative; height: 300px; }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }

        .stat-card {
            background: var(--bg-secondary);
            border-radius: 10px;
            padding: 15px;
            text-align: center;
            border: 1px solid var(--border-color);
        }

        .stat-value { font-size: 1.8rem; font-weight: 700; margin-bottom: 5px; }
        .stat-label { font-size: 0.75rem; color: var(--text-secondary); text-transform: uppercase; }
        .stat-value.green { color: var(--accent-green); }
        .stat-value.yellow { color: var(--accent-yellow); }
        .stat-value.red { color: var(--accent-red); }
        .stat-value.blue { color: var(--accent-blue); }

        .full-width { grid-column: 1 / -1; }

        .progress-table { width: 100%; border-collapse: collapse; }
        .progress-table th, .progress-table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }
        .progress-table th { color: var(--text-secondary); font-weight: 500; font-size: 0.85rem; text-transform: uppercase; }
        .progress-table tr:hover { background: rgba(59, 130, 246, 0.1); }

        .version-badge {
            display: inline-block;
            padding: 4px 10px;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 600;
        }
        .version-badge.v1 { background: #374151; color: #9ca3af; }
        .version-badge.v2 { background: #1e3a5f; color: #60a5fa; }
        .version-badge.v3 { background: #14532d; color: #4ade80; }

        .model-badge {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.75rem;
            background: var(--bg-primary);
            color: var(--text-secondary);
        }

        .rate-bar { width: 100%; height: 8px; background: var(--bg-primary); border-radius: 4px; overflow: hidden; }
        .rate-bar-fill { height: 100%; border-radius: 4px; transition: width 0.3s; }

        .trend-indicator { display: inline-flex; align-items: center; gap: 4px; font-size: 0.85rem; }
        .trend-up { color: var(--accent-green); }
        .trend-down { color: var(--accent-red); }
        .trend-same { color: var(--text-secondary); }

        .suggestions-list { list-style: none; }
        .suggestions-list li {
            padding: 12px;
            border-left: 3px solid var(--accent-blue);
            background: rgba(59, 130, 246, 0.1);
            margin-bottom: 10px;
            border-radius: 0 8px 8px 0;
        }
        .suggestions-list li.validated { border-left-color: var(--accent-green); background: rgba(34, 197, 94, 0.1); }

        .suggestion-status { font-size: 0.75rem; padding: 2px 8px; border-radius: 4px; margin-left: 8px; }
        .suggestion-status.validated { background: var(--accent-green); color: white; }
        .suggestion-status.proposed { background: var(--accent-yellow); color: #000; }
        .suggestion-status.applied { background: var(--accent-green); color: white; }
        .suggestion-status.pending { background: var(--accent-yellow); color: #000; }
        .suggestion-status.data-fix { background: var(--accent-red); color: white; }

        .version-card { background: var(--bg-primary); border-radius: 8px; padding: 15px; margin-bottom: 15px; border-left: 4px solid var(--accent-blue); }
        .version-card.has-improvements { border-left-color: var(--accent-green); }
        .version-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px; }
        .version-title { font-weight: 600; font-size: 1rem; }
        .version-meta { font-size: 0.8rem; color: var(--text-secondary); }
        .improvement-item { padding: 8px 12px; background: rgba(34, 197, 94, 0.1); border-radius: 6px; margin: 8px 0; font-size: 0.85rem; }
        .improvement-item .rubric { color: var(--accent-green); font-weight: 500; }
        .improvement-item .change { color: var(--text-secondary); margin-top: 4px; font-size: 0.8rem; }
        .no-improvements { color: var(--text-secondary); font-style: italic; font-size: 0.85rem; }

        /* Model Cost Matrix Styles */
        .model-matrix { width: 100%; border-collapse: collapse; margin-top: 10px; }
        .model-matrix th, .model-matrix td {
            padding: 10px 8px;
            text-align: center;
            border: 1px solid var(--border-color);
            font-size: 0.85rem;
        }
        .model-matrix th {
            background: var(--bg-primary);
            color: var(--text-secondary);
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.75rem;
        }
        .model-matrix th.provider-header {
            font-size: 0.7rem;
            letter-spacing: 1px;
            background: linear-gradient(135deg, var(--bg-primary), var(--bg-secondary));
        }
        .model-matrix .model-name {
            font-weight: 600;
            color: var(--text-primary);
            text-align: left;
            padding-left: 15px;
        }
        .model-matrix .cost-cell {
            font-family: 'Courier New', monospace;
            font-weight: 500;
        }
        .model-matrix .cost-cell.recommended {
            background: rgba(34, 197, 94, 0.2);
            color: var(--accent-green);
            font-weight: 700;
            position: relative;
        }
        .model-matrix .cost-cell.recommended::after {
            content: 'â˜…';
            position: absolute;
            top: 2px;
            right: 4px;
            font-size: 0.6rem;
            color: var(--accent-green);
        }
        .model-matrix .cost-cell.good {
            background: rgba(59, 130, 246, 0.15);
            color: var(--accent-blue);
        }
        .model-matrix .cost-cell.expensive {
            background: rgba(239, 68, 68, 0.15);
            color: var(--accent-red);
        }
        .model-matrix .cost-cell.moderate {
            background: rgba(234, 179, 8, 0.15);
            color: var(--accent-yellow);
        }
        .model-provider-badge {
            display: inline-block;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.7rem;
            font-weight: 600;
            margin-left: 6px;
        }
        .model-provider-badge.openai { background: #74aa9c; color: white; }
        .model-provider-badge.google { background: #4285f4; color: white; }
        .model-provider-badge.anthropic { background: #d97706; color: white; }
        .model-legend {
            display: flex;
            gap: 15px;
            margin-top: 15px;
            flex-wrap: wrap;
        }
        .legend-item {
            display: flex;
            align-items: center;
            gap: 6px;
            font-size: 0.75rem;
            color: var(--text-secondary);
        }
        .legend-color {
            width: 12px;
            height: 12px;
            border-radius: 3px;
        }
        .legend-color.recommended { background: rgba(34, 197, 94, 0.4); }
        .legend-color.good { background: rgba(59, 130, 246, 0.3); }
        .legend-color.moderate { background: rgba(234, 179, 8, 0.3); }
        .legend-color.expensive { background: rgba(239, 68, 68, 0.3); }
        .module-type-info {
            display: flex;
            gap: 20px;
            margin-bottom: 15px;
            padding: 12px;
            background: var(--bg-primary);
            border-radius: 8px;
        }
        .type-item {
            display: flex;
            flex-direction: column;
            gap: 2px;
        }
        .type-label { font-size: 0.7rem; color: var(--text-secondary); text-transform: uppercase; }
        .type-value { font-size: 0.9rem; color: var(--text-primary); font-weight: 500; }
        .dataset-stats {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 10px;
            margin-bottom: 15px;
        }
        .dataset-stat {
            background: var(--bg-primary);
            padding: 10px;
            border-radius: 6px;
            text-align: center;
        }
        .dataset-stat-value { font-size: 1.2rem; font-weight: 700; color: var(--accent-blue); }
        .dataset-stat-label { font-size: 0.7rem; color: var(--text-secondary); text-transform: uppercase; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ðŸ“ˆ Prompt Version Progress Dashboard</h1>
            <p>Track LLM Judge Pass Rate & Match Rate across prompt versions and models</p>
        </header>

        <div class="module-selector" id="moduleSelector"></div>
        <div class="stats-grid" id="statsGrid"></div>

        <div class="dashboard-grid">
            <div class="card">
                <h2>Pass Rate by Version</h2>
                <div class="chart-container"><canvas id="passRateChart"></canvas></div>
            </div>
            <div class="card">
                <h2>Model Comparison</h2>
                <div class="chart-container"><canvas id="modelCompareChart"></canvas></div>
            </div>
            <div class="card full-width">
                <h2>Version History</h2>
                <table class="progress-table" id="progressTable">
                    <thead>
                        <tr>
                            <th>Module</th>
                            <th>Version</th>
                            <th>Model</th>
                            <th>Dataset</th>
                            <th>Pass Rate</th>
                            <th>Match Rate</th>
                            <th>Pass/Fail</th>
                            <th>Trend</th>
                            <th>BT Link</th>
                        </tr>
                    </thead>
                    <tbody></tbody>
                </table>
            </div>
            <div class="card full-width">
                <h2>Applied Improvements (by Version)</h2>
                <div id="appliedImprovements"></div>
            </div>

            <div class="card full-width">
                <h2>Model Cost Matrix</h2>
                <p style="color: var(--text-secondary); font-size: 0.85rem; margin-bottom: 15px;">
                    Estimated costs for running this module's dataset through available models (via OpenAI & Gemini API keys)
                </p>
                <div id="moduleTypeInfo" class="module-type-info"></div>
                <div id="datasetStats" class="dataset-stats"></div>
                <table class="model-matrix" id="modelCostMatrix">
                    <thead>
                        <tr>
                            <th rowspan="2" style="text-align: left; width: 200px;">Model</th>
                            <th colspan="3" class="provider-header">Pricing (per 1M tokens)</th>
                            <th rowspan="2">Est. Cost</th>
                            <th rowspan="2">Quality</th>
                            <th rowspan="2">Speed</th>
                        </tr>
                        <tr>
                            <th>Input</th>
                            <th>Output</th>
                            <th>Total*</th>
                        </tr>
                    </thead>
                    <tbody id="modelCostBody"></tbody>
                </table>
                <div class="model-legend">
                    <div class="legend-item"><div class="legend-color recommended"></div>â˜… Recommended for this task</div>
                    <div class="legend-item"><div class="legend-color good"></div>Good value</div>
                    <div class="legend-item"><div class="legend-color moderate"></div>Moderate cost</div>
                    <div class="legend-item"><div class="legend-color expensive"></div>Expensive</div>
                </div>
                <p style="margin-top: 12px; font-size: 0.75rem; color: var(--text-secondary);">
                    * Costs estimated based on avg ~1500 input + ~300 output tokens/record. Actual costs may vary.
                </p>
            </div>

            <div class="card full-width">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                    <h2 style="margin: 0;">Improvement History by Version</h2>
                    <a href="MODULE_ANALYSIS_DASHBOARD.html" target="_blank" style="color: var(--accent-blue); text-decoration: none; font-size: 0.9rem;">
                        View Detailed Rubric Analysis â†’
                    </a>
                </div>
                <div id="suggestionsList"></div>
            </div>
        </div>
    </div>

    <script>
        const progressData = [
  {
    "data_source": "M01_V3_ExtractOwnBrandEntities_v3_190126_gpt5.csv",
    "dataset_version": "v3",
    "match_rate": 40.0,
    "model": "gpt-5",
    "module": "m01_v3",
    "pass_rate": 60.0,
    "prompt_version": "v3",
    "rubrics_version": "v5",
    "run_id": "m01_judge_20260120_003124",
    "summary": {
      "error": 0,
      "fail": 20,
      "pass": 30
    },
    "timestamp": "2026-01-20T00:31:24.366747",
    "total_evaluations": 50,
    "braintrust_id": "34958fa0-920a-4e5c-92d1-aca1e8928381",
    "braintrust_name": "M01_V3_ExtractOwnBrandEntities_v3_190126_gpt5",
    "dataset_id": "ecb73ce1-0090-40ef-bceb-0d71105aeca6",
    "dataset_name": "M01_ExtractOwnBrandEntities_V3",
    "prompt_id": "c5acb5f9-c12f-4c07-a6bf-9ab852c34b6b",
    "prompt_version_id": "1000196515183306932",
    "temperature": 0,
    "created": "2026-01-19 17:40:09.715000+00:00"
  },
  {
    "data_source": "M01_ExtractOwnBrandEntities_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 10.0,
    "model": "gpt-4o-mini",
    "module": "m01_v1",
    "pass_rate": 30.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m01_v1_judge_20260120_003146",
    "summary": {
      "error": 0,
      "fail": 35,
      "pass": 15
    },
    "timestamp": "2026-01-20T00:31:46.961853",
    "total_evaluations": 50,
    "braintrust_id": "e6720eee-6f86-4b87-966b-0591de5ce8a5",
    "braintrust_name": "M01_ExtractOwnBrandEntities_V1",
    "dataset_id": "e2d331a7-e757-4b66-b87d-97151470a11e",
    "dataset_name": "M01_ExtractOwnBrandEntities_V1.1",
    "prompt_id": "df8c6f85-a4d3-4d14-b1a0-7e5bb656a31e",
    "prompt_version_id": "1000196492750038047",
    "temperature": 0,
    "created": "2026-01-15 18:24:47.415000+00:00"
  },
  {
    "data_source": "M01_V2_ExtractOwnBrandEntities_v3_190126_1.csv",
    "dataset_version": "v2",
    "match_rate": 70.0,
    "model": "gpt-4o-mini",
    "module": "m01_v3",
    "pass_rate": 70.0,
    "prompt_version": "v3",
    "rubrics_version": "v5",
    "run_id": "m01_v2_judge_20260120_003101",
    "summary": {
      "error": 0,
      "fail": 15,
      "pass": 35
    },
    "timestamp": "2026-01-20T00:31:01.912936",
    "total_evaluations": 50,
    "braintrust_id": "2d13701c-caa4-47dc-9e79-3536dff50b9e",
    "braintrust_name": "M01_V3_ExtractOwnBrandEntities_v3_190126_1",
    "dataset_id": "ecb73ce1-0090-40ef-bceb-0d71105aeca6",
    "dataset_name": "M01_ExtractOwnBrandEntities_V3",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-19 16:32:09.726000+00:00"
  },
  {
    "data_source": "M01A_ExtractOwnBrandVariations_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m01a",
    "pass_rate": 90.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m01a_judge_20260120_003132",
    "summary": {
      "error": 0,
      "fail": 4,
      "pass": 36
    },
    "timestamp": "2026-01-20T00:31:32.403534",
    "total_evaluations": 40,
    "braintrust_id": "d6efa0aa-dcfa-436f-b9ea-1286b132cce7",
    "braintrust_name": "M01A_ExtractOwnBrandVariations_v1",
    "dataset_id": "77aa12e9-c829-4dd4-834e-658b08016a56",
    "dataset_name": "M01A_ExtractOwnBrandVariations_V1.1",
    "prompt_id": "416420ef-b087-4f2b-9ef5-d82edf7cdfbf",
    "prompt_version_id": "1000196492768459099",
    "temperature": 0,
    "created": "2026-01-15 18:33:24.651000+00:00"
  },
  {
    "data_source": "M01A_V2_ExtractOwnBrandVariations_v2_190126_gpt5.csv",
    "dataset_version": "v2",
    "match_rate": 0,
    "model": "gpt-5",
    "module": "m01a_v2",
    "pass_rate": 85.0,
    "prompt_version": "v2",
    "rubrics_version": "v5",
    "run_id": "m01a_v2_judge_20260120_004925",
    "summary": {
      "error": 0,
      "fail": 6,
      "pass": 34
    },
    "timestamp": "2026-01-20T00:49:25.922974",
    "total_evaluations": 40,
    "braintrust_id": "93256f77-c7f1-454d-aaca-9e783c0e94e6",
    "braintrust_name": "M01A_V2_ExtractOwnBrandVariations_v2_190126_gpt5",
    "dataset_id": "f651668c-997f-43fc-81ac-5bc00626c497",
    "dataset_name": "M01A_V2_ExtractOwnBrandVariations",
    "prompt_id": "7d24e0f6-30f0-4c3c-972e-568e12006701",
    "prompt_version_id": "1000196515592466206",
    "temperature": 0.3,
    "created": "2026-01-19 19:36:19.492000+00:00"
  },
  {
    "data_source": "M01B_ExtractBrandRelatedTerms_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m01b",
    "pass_rate": 73.3,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m01b_judge_20260119_151915",
    "summary": {
      "error": 0,
      "fail": 16,
      "pass": 44
    },
    "timestamp": "2026-01-19T15:19:15.844191",
    "total_evaluations": 60,
    "braintrust_id": "001ee360-9389-4b79-aa7a-f0112b3b5d60",
    "braintrust_name": "M01B_ExtractBrandRelatedTerms_v1",
    "dataset_id": "4136035d-c741-459b-a107-6b185a92aa7b",
    "dataset_name": "M01B_ExtractBrandRelatedTerms_V1.1",
    "prompt_id": "8b4a666e-b140-4ba7-ba67-6be650f3a8b0",
    "prompt_version_id": "1000196492804019857",
    "temperature": 0,
    "created": "2026-01-15 18:36:40.366000+00:00"
  },
  {
    "data_source": "M02_ClassifyOwnBrandKeywords_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m02",
    "pass_rate": 100.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m02_judge_20260119_152217",
    "summary": {
      "error": 0,
      "fail": 0,
      "pass": 105
    },
    "timestamp": "2026-01-19T15:22:17.082655",
    "total_evaluations": 105,
    "braintrust_id": "6bf7505b-f415-4402-8cda-2900dcda62c3",
    "braintrust_name": "M02_ClassifyOwnBrandKeywords-cb97caef",
    "dataset_id": "53159951-ee6a-48b4-aad4-ae602e0b0c99",
    "dataset_name": "M02_ClassifyOwnBrandKeywords_V1.1",
    "prompt_id": "52bb2595-e579-44ca-ab2d-30e567049246",
    "prompt_version_id": "1000196491395355933",
    "temperature": 0,
    "created": "2026-01-15 13:02:23.977000+00:00"
  },
  {
    "data_source": "M02B_ClassifyOwnBrandKeywords_PathB_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m02b",
    "pass_rate": 100.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m02b_judge_20260120_005124",
    "summary": {
      "error": 0,
      "fail": 0,
      "pass": 70
    },
    "timestamp": "2026-01-20T00:51:24.520681",
    "total_evaluations": 70,
    "braintrust_id": "b45f1d36-8d7a-4ceb-8525-38a27b38cac5",
    "braintrust_name": "M02B_ClassifyOwnBrandKeywords_PathB_v1",
    "dataset_id": "7810034c-ef1c-4b0b-b78e-56c3f09754a7",
    "dataset_name": "M02B_ClassifyOwnBrandKeywords_PathB_V1.1",
    "prompt_id": "59b529ec-84e4-4678-93b0-a0781cd80234",
    "prompt_version_id": "1000196493217005689",
    "temperature": 0,
    "created": "2026-01-15 20:23:56.978000+00:00"
  },
  {
    "data_source": "M04_ClassifyCompetitorBrandKeywords_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m04",
    "pass_rate": 60.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m04_judge_20260119_204721",
    "summary": {
      "error": 0,
      "fail": 24,
      "pass": 36
    },
    "timestamp": "2026-01-19T20:47:21.027981",
    "total_evaluations": 60,
    "braintrust_id": "97867488-a3d2-4048-a251-a440c9275e49",
    "braintrust_name": "M04_ClassifyCompetitorBrandKeywords-bfc88c43",
    "dataset_id": "4f84a83f-088b-423a-9e87-3c90822c056f",
    "dataset_name": "M04_ClassifyCompetitorBrandKeywords_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 12:13:54.707000+00:00"
  },
  {
    "data_source": "M04B_ClassifyCompetitorBrandKeywords_PathB_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m04b",
    "pass_rate": 80.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m04b_judge_20260120_005238",
    "summary": {
      "error": 0,
      "fail": 8,
      "pass": 32
    },
    "timestamp": "2026-01-20T00:52:38.747693",
    "total_evaluations": 40,
    "braintrust_id": "93833f92-2aae-4d11-91fc-5a596d6eabf1",
    "braintrust_name": "M04B_ClassifyCompetitorBrandKeywords_PathB_v1",
    "dataset_id": "6173da1f-a3e4-4b1b-adb2-fabb2651b84f",
    "dataset_name": "M04B_ClassifyCompetitorBrandKeywords_PathB",
    "prompt_id": "2e81badf-ce5f-46da-9eec-d7b6f91584d7",
    "prompt_version_id": "1000196493004416041",
    "temperature": 0,
    "created": "2026-01-15 21:08:57.044000+00:00"
  },
  {
    "data_source": "M05_ClassifyNonBrandedKeywords_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m05",
    "pass_rate": 100.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m05_judge_20260120_002750",
    "summary": {
      "error": 0,
      "fail": 0,
      "pass": 4
    },
    "timestamp": "2026-01-20T00:27:50.770592",
    "total_evaluations": 4,
    "braintrust_id": "ae3bdb06-9db8-46b7-897c-6e14e8d34c70",
    "braintrust_name": "M05_ClassifyNonBrandedKeywords_v1",
    "dataset_id": "2b96246a-a4ec-4a26-a2b7-fc0371381f81",
    "dataset_name": "M05_ClassifyNonbrandedKeywords_V1.1",
    "prompt_id": "b591351d-6a14-42e2-8783-357c8b1556ab",
    "prompt_version_id": "1000196493232508940",
    "temperature": 0,
    "created": "2026-01-15 20:32:44.127000+00:00"
  },
  {
    "data_source": "M05B_ClassifyNonBrandedKeywords_PathB_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m05b",
    "pass_rate": 90.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m05b_judge_20260120_005310",
    "summary": {
      "error": 0,
      "fail": 2,
      "pass": 18
    },
    "timestamp": "2026-01-20T00:53:10.880745",
    "total_evaluations": 20,
    "braintrust_id": "546e570b-9b65-4eed-b08b-549b1bf408cd",
    "braintrust_name": "M05B_ClassifyNonBrandedKeywords_PathB_v1",
    "dataset_id": "a6e9b14a-702e-4ab8-bc82-1d30583a2d19",
    "dataset_name": "M05B_ClassifyNonBrandedKeywords_PathB_V1.1",
    "prompt_id": "793a831d-202f-496b-8629-2cadaf8d49d5",
    "prompt_version_id": "1000196492864935133",
    "temperature": 0,
    "created": "2026-01-15 19:56:51.514000+00:00"
  },
  {
    "data_source": "M06_GenerateProductTypeTaxonomy_gd1_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m06_gd",
    "pass_rate": 65.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m06_gd_judge_20260120_005445",
    "summary": {
      "error": 0,
      "fail": 21,
      "pass": 39
    },
    "timestamp": "2026-01-20T00:54:45.854644",
    "total_evaluations": 60,
    "braintrust_id": "72ed5c87-3d3a-4853-ace0-baba0bbbf81e",
    "braintrust_name": "M06_GenerateProductTypeTaxonomy_GD_v1",
    "dataset_id": "cce4a191-6a25-4185-8675-4bda102226da",
    "dataset_name": "M06_GenerateProductTypeTaxonomy_V1.1",
    "prompt_id": "ee5bb5ac-b613-4579-b462-a9b61455d34b",
    "prompt_version_id": "1000196486895942787",
    "temperature": 0,
    "created": "2026-01-15 21:29:31.014000+00:00"
  },
  {
    "data_source": "M06_GenerateProductTypeTaxonomy_sd1_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m06_sd",
    "pass_rate": 65.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m06_sd_judge_20260120_005620",
    "summary": {
      "error": 0,
      "fail": 21,
      "pass": 39
    },
    "timestamp": "2026-01-20T00:56:20.386036",
    "total_evaluations": 60,
    "braintrust_id": "7158973d-d40a-4d32-ad37-81805bb5831d",
    "braintrust_name": "M06_GenerateProductTypeTaxonomy-SD_v1",
    "dataset_id": "aaae9cbd-92a3-4642-809e-c53f4eec5168",
    "dataset_name": "M06_V2_GenerateProductTypeTaxonomy",
    "prompt_id": "ee5bb5ac-b613-4579-b462-a9b61455d34b",
    "prompt_version_id": "1000196486895942787",
    "temperature": 0,
    "created": "2026-01-14 17:32:51.387000+00:00"
  },
  {
    "data_source": "M07_ExtractProductAttributes_gd1_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m07_gd",
    "pass_rate": 75.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m07_gd_judge_20260120_005734",
    "summary": {
      "error": 0,
      "fail": 10,
      "pass": 30
    },
    "timestamp": "2026-01-20T00:57:34.663211",
    "total_evaluations": 40,
    "braintrust_id": "a1086652-afcf-4ea5-aaf4-31fb888ae0e0",
    "braintrust_name": "M07_ExtractProductAttributes_gd_v1",
    "dataset_id": "27a50f6b-44da-4144-b897-85f4de1600b8",
    "dataset_name": "M07_ExtractProductAttributes_V1.1",
    "prompt_id": "d6da55ae-54fc-4706-9cbe-8e5636151372",
    "prompt_version_id": "1000196493521759930",
    "temperature": 0,
    "created": "2026-01-15 21:37:51.439000+00:00"
  },
  {
    "data_source": "M07_ExtractProductAttributes-sd1_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m07_sd",
    "pass_rate": 77.5,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m07_sd_judge_20260120_005857",
    "summary": {
      "error": 0,
      "fail": 9,
      "pass": 31
    },
    "timestamp": "2026-01-20T00:58:57.315491",
    "total_evaluations": 40,
    "braintrust_id": "7e1412bd-2304-4b3a-95b7-4ddbfbef6961",
    "braintrust_name": "M07_ExtractProductAttributes-SD1_v1",
    "dataset_id": "8d3adb98-a8bc-4bed-9162-b79a94dc238c",
    "dataset_name": "M07_V2_ExtractProductAttributes",
    "prompt_id": "c10225d0-4dbf-4b7d-8daa-80124142fdca",
    "prompt_version_id": "1000196486904202773",
    "temperature": 0,
    "created": "2026-01-14 17:51:56.531000+00:00"
  },
  {
    "data_source": "M08_AssignAttributeRanks_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o",
    "module": "m08",
    "pass_rate": 5.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m08_judge_20260120_010035",
    "summary": {
      "error": 0,
      "fail": 38,
      "pass": 2
    },
    "timestamp": "2026-01-20T01:00:35.082566",
    "total_evaluations": 40,
    "braintrust_id": "be61b01a-7ec1-441a-a767-c839302022b2",
    "braintrust_name": "M08_AssignAttributeRanks-6d9e5ce6",
    "dataset_id": "5c325eb0-6e7d-4b25-bee0-6847fc4ce263",
    "dataset_name": "M08_AssignAttributeRanks_V1.1",
    "prompt_id": "992eaa83-fd62-4308-a31e-d7543b6c0742",
    "prompt_version_id": "1000196486131603668",
    "temperature": 0,
    "created": "2026-01-14 14:18:03.930000+00:00",
    "note": "m08_sd REMOVED - contained M07 data (invalid)"
  },
  {
    "data_source": "M08_V2_AssignAttributeRanks_v1_150126_1.csv",
    "dataset_version": "v2",
    "match_rate": 0,
    "model": "gpt-4o",
    "module": "m08_v2",
    "pass_rate": 7.5,
    "prompt_version": "v2",
    "rubrics_version": "v5",
    "run_id": "m08_v2_judge_20260120_010415",
    "summary": {
      "error": 0,
      "fail": 37,
      "pass": 3
    },
    "timestamp": "2026-01-20T01:04:15.956521",
    "total_evaluations": 40,
    "braintrust_id": "0ef768c9-04dd-45b6-a6d3-d3a33f763d63",
    "braintrust_name": "M08_V2_AssignAttributeRanks_v1",
    "dataset_id": "5c325eb0-6e7d-4b25-bee0-6847fc4ce263",
    "dataset_name": "M08_AssignAttributeRanks_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 20:36:55.613000+00:00"
  },
  {
    "data_source": "M08_V2_AssignAttributeRanks-sd1_v1_150126_1.csv",
    "dataset_version": "v2",
    "match_rate": 0,
    "model": "gpt-4o",
    "module": "m08_v2_sd",
    "pass_rate": 52.5,
    "prompt_version": "v2",
    "rubrics_version": "v5",
    "run_id": "m08_v2_sd_judge_20260120_010557",
    "summary": {
      "error": 0,
      "fail": 19,
      "pass": 21
    },
    "timestamp": "2026-01-20T01:05:57.604187",
    "total_evaluations": 40,
    "braintrust_id": "e7eeca50-cb96-4276-ac15-cb50420d2341",
    "braintrust_name": "M08_V2_AssignAttributeRanks-sd1_v1",
    "dataset_id": "08dd82c4-6e93-4eaa-8612-5e727dd404e9",
    "dataset_name": "M08_SD1_AssignAttributeRanks",
    "prompt_id": "e632d218-b335-47ac-aba4-5f80864981f3",
    "prompt_version_id": "1000196487582052816",
    "temperature": 0,
    "created": "2026-01-14 20:54:53.936000+00:00"
  },
  {
    "data_source": "M09_IdentifyPrimaryIntendedUse_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m09",
    "pass_rate": 62.5,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m09_judge_20260120_010658",
    "summary": {
      "error": 0,
      "fail": 15,
      "pass": 25
    },
    "timestamp": "2026-01-20T01:06:58.509576",
    "total_evaluations": 40,
    "braintrust_id": "273035ae-7b24-4cd5-92f2-eab70c66c836",
    "braintrust_name": "M09_IdentifyPrimaryIntendedUse_V1.1",
    "dataset_id": "a8fdb7f3-c58e-4bc0-8153-a58cd50c8bc6",
    "dataset_name": "M09_IdentifyPrimaryIntendedUse_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 21:45:34.554000+00:00"
  },
  {
    "data_source": "M10_ValidatePrimaryIntendedUse_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m10",
    "pass_rate": 20.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m10_judge_20260120_010748",
    "summary": {
      "error": 0,
      "fail": 16,
      "pass": 4
    },
    "timestamp": "2026-01-20T01:07:48.837867",
    "total_evaluations": 20,
    "braintrust_id": "1f3b3531-a143-4195-88c5-a91458cf9d03",
    "braintrust_name": "M10_ValidatePrimaryIntendedUse_V1.1_v1",
    "dataset_id": "329287b2-4ebd-472c-8db3-f7e731cc56e7",
    "dataset_name": "M10_ValidatePrimaryIntendedUse_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 21:46:50.968000+00:00"
  },
  {
    "data_source": "M11_IdentifyHardConstraints_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m11",
    "pass_rate": 52.9,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m11_judge_20260120_011020",
    "summary": {
      "error": 0,
      "fail": 33,
      "pass": 37
    },
    "timestamp": "2026-01-20T01:10:20.800444",
    "total_evaluations": 70,
    "braintrust_id": "e94e9edc-22af-48c5-b151-ba9af6dc2996",
    "braintrust_name": "M11_IdentifyHardConstraints_V1.1_v1",
    "dataset_id": "7f15bfc1-4541-4652-a667-bb1842b43e46",
    "dataset_name": "M11_IdentifyHardConstraints_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 22:15:16.479000+00:00"
  },
  {
    "data_source": "M12_HardConstraintViolationCheck_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m12",
    "pass_rate": 60.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m12_judge_20260120_011056",
    "summary": {
      "error": 0,
      "fail": 8,
      "pass": 12
    },
    "timestamp": "2026-01-20T01:10:56.991676",
    "total_evaluations": 20,
    "braintrust_id": "f880cfd8-af50-4a71-8e66-90311a9a64a8",
    "braintrust_name": "M12_HardConstraintViolationCheck_v1_20260115_1",
    "dataset_id": "cf2c2974-09d6-41b7-93b1-272d3c7e2716",
    "dataset_name": "M12_CheckHardConstraint_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-16 07:59:20.368000+00:00"
  },
  {
    "data_source": "M13_ProductTypeCheck_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m13",
    "pass_rate": 90.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m13_judge_20260120_011158",
    "summary": {
      "error": 0,
      "fail": 3,
      "pass": 27
    },
    "timestamp": "2026-01-20T01:11:58.977590",
    "total_evaluations": 30,
    "braintrust_id": "f02822df-b216-43a8-bb07-eacdc90f2ed3",
    "braintrust_name": "M13_ProductTypeCheck_V1.1_v1",
    "dataset_id": "25532e83-5425-401e-9a3a-50782d574776",
    "dataset_name": "M13_CheckProductType_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 22:23:42.797000+00:00"
  },
  {
    "data_source": "M14_PrimaryUseCheckSameType_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m14",
    "pass_rate": 100.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m14_judge_20260120_011314",
    "summary": {
      "error": 0,
      "fail": 0,
      "pass": 30
    },
    "timestamp": "2026-01-20T01:13:14.384437",
    "total_evaluations": 30,
    "braintrust_id": "9bec004e-4a1c-4df7-b7b4-23d13e8973e5",
    "braintrust_name": "M14_PrimaryUseCheckSameType_V1.1_v1",
    "dataset_id": "498ae6c2-1bfa-44a3-9948-889856d6d796",
    "dataset_name": "M14_CheckPrimaryUseSameType_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 22:26:24.937000+00:00"
  },
  {
    "data_source": "M15_SubstituteCheck_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m15",
    "pass_rate": 95.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m15_judge_20260120_011405",
    "summary": {
      "error": 0,
      "fail": 1,
      "pass": 19
    },
    "timestamp": "2026-01-20T01:14:05.532752",
    "total_evaluations": 20,
    "braintrust_id": "20ad9832-cec0-4e7c-96de-70984a9b7976",
    "braintrust_name": "M15_SubstituteCheck_V1.1_v1",
    "dataset_id": "48c73d5b-c15c-4e63-ae61-fb040bf65543",
    "dataset_name": "M15_CheckSubstitute_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 22:28:58.660000+00:00"
  },
  {
    "data_source": "M16_ComplementaryCheck_v1_150126_1.csv",
    "dataset_version": null,
    "match_rate": 0,
    "model": "gpt-4o-mini",
    "module": "m16",
    "pass_rate": 75.0,
    "prompt_version": "v1",
    "rubrics_version": "v5",
    "run_id": "m16_judge_20260120_011538",
    "summary": {
      "error": 0,
      "fail": 10,
      "pass": 30
    },
    "timestamp": "2026-01-20T01:15:38.333262",
    "total_evaluations": 40,
    "braintrust_id": "12b05ae7-e0c4-48c8-a7bb-e07b3cc1b95a",
    "braintrust_name": "M16_ComplementaryCheck_V1.1_v1",
    "dataset_id": "af991abf-dce7-4155-b279-6b98cae77f86",
    "dataset_name": "M16_CheckComplementary_V1.1",
    "prompt_id": null,
    "prompt_version_id": null,
    "temperature": 0,
    "created": "2026-01-15 22:31:40.360000+00:00"
  },
  {
    "run_id": "m01_v2_judge_20260120_014252",
    "module": "m01_v2",
    "prompt_version": "v2",
    "dataset_version": null,
    "model": "gpt-4o",
    "rubrics_version": "v5",
    "timestamp": "2026-01-20T01:42:52.118402",
    "data_source": "M01_ExtractOwnBrandEntities_v2_190126_1.csv",
    "summary": {
      "pass": 45,
      "fail": 55,
      "error": 0
    },
    "pass_rate": 45.0,
    "match_rate": 30.0,
    "total_evaluations": 100,
    "braintrust_id": "055d0fdd-56a6-414b-9c05-a4a7ae514dc9",
    "braintrust_name": "M01_V2_ExtractOwnBrandEntities_v3_190126_1",
    "dataset_id": "ecb73ce1-0090-40ef-bceb-0d71105aeca6",
    "dataset_name": "M01_ExtractOwnBrandEntities_V3",
    "prompt_id": "421c42b9-6270-48c3-bb8e-2f66c7d13817",
    "prompt_version_id": "1000196514722422966",
    "temperature": 0,
    "created": "2026-01-19 15:29:41.876000+00:00"
  }
];
        const suggestionsData = [
  {
    "rubric": "No Hallucinated Brand",
    "criticality": "High",
    "passRate": 60.0,
    "issueType": "Model Issue + Prompt Clarity",
    "analysisSummary": "Model extracts 'Vibe' as standalone sub-brand from 'Vibe Beam' when prompt says to skip entire sub-brand if last word is generic",
    "specificIssue": "For JBL sample (B0BQPGJ9LQ), model outputs ['Vibe', 'vibe', 'Vibbe', 'Vieb'] as standalone entities. The prompt clearly states that 'Vibe Beam' should be REMOVED because 'beam' is a generic word. The model is extracting just the first part instead of skipping entirely.",
    "expectedOutput": "NO 'Vibe' entities - should only extract 'JBL' and its typos",
    "actualOutput": "['JBL', 'jbl', 'JLB', 'JBLl', 'JBLB', 'Vibe', 'vibe', 'Vibbe', 'Vieb']",
    "detailedSuggestion": "PROMPT FIX: Add explicit rule - 'When a sub-brand like [Brand] [SubBrand] fails the test because the last word is generic, DO NOT extract the first part separately. Skip the ENTIRE sub-brand.' The model is partially applying the rule by removing 'Beam' but keeping 'Vibe'.",
    "promptChange": "Add to prompt: \"### IMPORTANT: If sub-brand fails Amazon Test, skip ENTIRE sub-brand\\n- JBL Vibe Beam -> 'beam' is generic -> DO NOT extract 'Vibe' separately -> skip entire sub-brand\\n- Only extract: JBL (main brand)\"",
    "impact": "Expected to improve from 60% to 90%+ for this rubric",
    "validated": false,
    "module": "M01"
  },
  {
    "rubric": "No Product Words in Brand",
    "criticality": "Medium",
    "passRate": 86.7,
    "issueType": "Model Issue",
    "analysisSummary": "AirPods being extracted as brand entity when it's a product word",
    "specificIssue": "For sample B0D1XD1ZV3, model extracts 'AirPods' and typos as brand entities. AirPods is a product category (you can buy AirPods on Amazon) not a brand entity in the context of third-party accessories.",
    "expectedOutput": "No 'AirPods' in output - only extract the actual third-party brand",
    "actualOutput": "['AirPods', 'airpods', 'AirPod', 'AirPdos']",
    "detailedSuggestion": "PROMPT FIX: Add 'AirPods' to list of product words to exclude. Also clarify that when listing is for 'compatible with AirPods' accessories, AirPods is the product category, not the brand to extract.",
    "promptChange": "Add to product words list: 'AirPods, AirPod, Earbuds, iPhone, iPad' - common Apple products that are product categories not brand entities for accessories",
    "impact": "Expected to improve from 86.7% to 95%+ for this rubric",
    "validated": false,
    "module": "M01"
  },
  {
    "rubric": "No Duplicate Entities",
    "criticality": "Medium",
    "passRate": 86.7,
    "issueType": "Model Issue",
    "analysisSummary": "Some outputs contain exact duplicate strings",
    "specificIssue": "Samples B08J8GZXKZ and B09LCKZBTW have exact duplicate strings in output. Model is not performing final deduplication check.",
    "expectedOutput": "All unique strings in output",
    "actualOutput": "'Town & Country Livng' appears twice, 'Sachsen-Usa' appears twice",
    "detailedSuggestion": "PROMPT FIX: Strengthen final validation step. Add bold instruction: '**FINAL CHECK: Before outputting, scan your list character by character. If ANY string appears more than once, DELETE the duplicate.**'",
    "promptChange": "Strengthen duplicate check instruction with explicit character-by-character verification",
    "impact": "Expected to improve from 86.7% to 98%+ for this rubric",
    "validated": false,
    "module": "M01"
  },
  {
    "rubric": "Correct CB/null Classification",
    "criticality": "Critical",
    "passRate": 33.3,
    "issueType": "Judge Issue (Data Quality)",
    "analysisSummary": "9 of 10 failures are DATA ISSUES - expected values say CB but brand NOT in competitor_entities list. Model correctly returned null.",
    "specificIssue": "Keywords like 'oven mitts oxo', 'blue q oven mitt', 'sur la table oven mitts', 'pioneer woman oven mitts', 'cuisinart oven mitts' have Expected='CB' but OXO, Blue Q, Sur La Table, Pioneer Woman, Cuisinart are NOT in the competitor_entities list. Model correctly returned null - the DATASET is wrong.",
    "expectedOutput": "null (brand not in competitor list per prompt rules)",
    "actualOutput": "null or empty (CORRECT behavior per prompt)",
    "detailedSuggestion": "DATA FIX: Update dataset expected values. When brand is not in competitor_entities list, expected should be null/empty, not CB. The rubric states: 'Only match against provided competitor_entities - don't assume unlisted brands are competitors'",
    "datasetChanges": [
      {
        "keyword": "oven mitts oxo",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "OXO not in competitor_entities"
      },
      {
        "keyword": "oxo oven mitts",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "OXO not in competitor_entities"
      },
      {
        "keyword": "blue q oven mitt",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "Blue Q not in competitor_entities"
      },
      {
        "keyword": "sur la table oven mitts",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "Sur La Table not in competitor_entities"
      },
      {
        "keyword": "oxo oven mitt",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "OXO not in competitor_entities"
      },
      {
        "keyword": "oxo silicone oven mitt",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "OXO not in competitor_entities"
      },
      {
        "keyword": "pioneer woman oven mitts",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "Pioneer Woman not in competitor_entities"
      },
      {
        "keyword": "cuisinart oven mitts",
        "current_expected": "CB",
        "correct_expected": "null",
        "reason": "Cuisinart not in competitor_entities"
      }
    ],
    "impact": "If dataset is fixed, pass rate would improve from 33.3% to ~90%",
    "validated": true,
    "validation_note": "Verified by checking competitor_entities list - none of these brands exist in list",
    "module": "M04"
  },
  {
    "rubric": "Case Insensitive Matching",
    "criticality": "High",
    "passRate": 40.0,
    "issueType": "Judge Issue (Data Quality) + Minor Prompt Issue",
    "analysisSummary": "8 of 9 failures are same DATA ISSUE as above. 1 failure (AGLUCKY) is model confusion.",
    "specificIssue": "Same data quality issue - judge fails these because expected='CB' but brand not in list. AGLUCKY case: model said 'AGLUCKY matches own brand entity' when own brand is 'Antarctic Star' - this is model confusion.",
    "expectedOutput": "CB for AGLUCKY (it IS in competitor list)",
    "actualOutput": "Empty - model incorrectly thought AGLUCKY was own brand",
    "detailedSuggestion": "PROMPT FIX for AGLUCKY edge case: The model saw 'AGLUCKY' in competitor list but confused it with own brand. Add clarification: 'NOTE: The own_brand is specified in input. competitor_entities is a SEPARATE list. Do not confuse them.'",
    "promptChange": "Add clarification in Phase 1: 'AGLUCKY is NOT an own_brand entity - check own_brand.entities field specifically, not competitor_entities'",
    "impact": "Minor improvement - 1 true failure would be fixed",
    "validated": true,
    "module": "M04"
  },
  {
    "rubric": "Competitor Correctly Identified",
    "criticality": "Medium",
    "passRate": 66.7,
    "issueType": "Judge Issue (Data Quality)",
    "analysisSummary": "4 of 5 failures are DATA ISSUES - same root cause. 1 failure (william sonoma) is model returning CB for unlisted brand.",
    "specificIssue": "For 'william sonoma oven mitts', model returned CB='CB' saying it's a recognized competitor, but William Sonoma is NOT in competitor_entities. This is model hallucinating a competitor.",
    "expectedOutput": "null (brand not in competitor list)",
    "actualOutput": "CB (incorrect - model assumed brand is competitor without checking list)",
    "detailedSuggestion": "PROMPT FIX: Strengthen instruction 'Only mark CB if brand EXACTLY appears in competitor_entities list. Do NOT assume well-known brands are competitors if not in list.'",
    "promptChange": "Add bold reminder: '**CRITICAL: Only CB if brand is IN competitor_entities. William Sonoma, Cuisinart, OXO are NOT competitors unless EXPLICITLY in list**'",
    "impact": "Would fix the william sonoma false positive",
    "validated": true,
    "module": "M04"
  },
  {
    "rubric": "Own Brand Excluded",
    "criticality": "Low",
    "passRate": 100.0,
    "issueType": "Excellent",
    "analysisSummary": "All 15 samples passed - model correctly excludes own brand from CB classification",
    "specificIssue": "No issues - this rubric is working correctly",
    "expectedOutput": "null when keyword contains own brand",
    "actualOutput": "null (correct)",
    "detailedSuggestion": "No changes needed",
    "impact": "Already at 100%",
    "validated": true,
    "module": "M04"
  },
  {
    "rubric": "8-12 Variations Generated",
    "criticality": "High",
    "passRate": 60.0,
    "issueType": "Model Issue",
    "analysisSummary": "4 of 10 samples fail due to DUPLICATE variations. Model generates 12 items but some are repeated.",
    "specificIssue": "Model outputs include duplicates: Jikasho has 'Jikashoo', 'Jikashu', 'Jikashp' repeated; Antarctic Star has 'Antarctic Staar' twice; WEBACOO has 'WEBACOOO' 3 times; Transformers has 'Transformers', 'Transformerss', 'Tranzformers' repeated.",
    "expectedOutput": "8-12 UNIQUE variations",
    "actualOutput": "12 items with duplicates = fewer than 8 unique",
    "detailedSuggestion": "PROMPT FIX: Strengthen the 'NO DUPLICATES' rule with explicit validation step. Add: '**FINAL CHECK: Before outputting, scan your list for exact string matches. Delete ALL duplicates - each variation must appear EXACTLY once.**'",
    "promptChange": "Add bold instruction: '## DUPLICATE CHECK\\n**CRITICAL**: Before returning, verify each string is unique. If you see ANY exact duplicate, DELETE it. Count unique items - must be 8-12.'",
    "impact": "Expected to improve from 60% to 90%+ for this rubric",
    "validated": true,
    "validation_note": "Verified by inspecting outputs - all failures are due to exact string duplicates",
    "module": "M01A"
  },
  {
    "rubric": "No Unrelated Terms",
    "criticality": "Low",
    "passRate": 90.0,
    "issueType": "Judge Issue",
    "analysisSummary": "1 false positive - judge incorrectly flagged 'KichenAid' as 'unrelated term' when it's a valid TYPO variation",
    "specificIssue": "For KitchenAid brand, judge marked 'KichenAid' (missing 't') as FAIL saying it's 'not a plausible reference to the brand'. This is WRONG - 'KichenAid' is clearly a keyboard typo where 't' was missed (t is next to y on QWERTY).",
    "expectedOutput": "PASS - typos are explicitly allowed per prompt",
    "actualOutput": "FAIL - judge misclassified typo as unrelated",
    "detailedSuggestion": "RUBRIC FIX: Update M01a_no_unrelated_terms rubric to explicitly state that TYPOS are valid variations. Add example: 'KichenAid' is a valid typo of 'KitchenAid' (missing t).",
    "rubricChange": "Add to pass_definition: 'Typos with missing/swapped letters are valid brand variations (e.g., KichenAid for KitchenAid)'",
    "impact": "Would correct 1 false positive per 10 samples (~10% improvement)",
    "validated": true,
    "validation_note": "KichenAid is clearly missing 't' - standard QWERTY typo",
    "module": "M01A"
  },
  {
    "rubric": "Variations Generated",
    "criticality": "Excellent",
    "passRate": 100.0,
    "issueType": "Excellent",
    "analysisSummary": "All 10 samples passed - model generates at least 3 variations correctly",
    "specificIssue": "No issues",
    "detailedSuggestion": "No changes needed",
    "impact": "Already at 100%",
    "validated": true,
    "module": "M01A"
  },
  {
    "rubric": "First Item is Correct Spelling",
    "criticality": "Excellent",
    "passRate": 100.0,
    "issueType": "Excellent",
    "analysisSummary": "All 10 samples passed - first item is always canonical spelling",
    "specificIssue": "No issues",
    "detailedSuggestion": "No changes needed",
    "impact": "Already at 100%",
    "validated": true,
    "module": "M01A"
  },
  {
    "rubric": "Ranks Assigned",
    "criticality": "Critical",
    "passRate": 5.0,
    "issueType": "Judge Issue + Model Issue",
    "analysisSummary": "CRITICAL: Judge expects 'Use Case' but prompt shows 'UseCase'. Model also skips ranking some attributes.",
    "specificIssue": "Prompt CLEARLY shows 'UseCase' (no space) in ALL examples: {\"attribute\": \"Echo Dot\", \"type\": \"UseCase\", \"rank\": 1}. But expected values and judge use 'Use Case' (with space). This spelling mismatch causes ~50% of failures. Additionally, model sometimes only ranks 6 attributes when 11 are present.",
    "expectedOutput": "'UseCase' as shown in prompt examples",
    "actualOutput": "'UseCase' (correct per prompt) marked as FAIL by judge expecting 'Use Case'",
    "detailedSuggestion": "FIX 1 (JUDGE): Update rubric/expected values to accept 'UseCase' (no space) as shown in prompt. FIX 2 (MODEL): Add instruction 'You MUST rank EVERY attribute. If 11 variants exist, output ranks 1-11 with no gaps.'",
    "promptChange": "Add: '**CRITICAL**: Rank ALL attributes. If there are N attributes, output exactly N ranked items with ranks 1 to N.'",
    "rubricChange": "Accept 'UseCase' spelling as valid (matches prompt examples)",
    "impact": "Expected to improve from 5% to 70%+ after fixing both issues",
    "validated": true,
    "validation_note": "Verified prompt shows UseCase in examples at lines 45-60",
    "module": "M08"
  },
  {
    "rubric": "Title Attributes Ranked 1-2",
    "criticality": "High",
    "passRate": 10.0,
    "issueType": "Model Issue",
    "analysisSummary": "Title attributes sometimes ranked 3+ instead of required 1-2",
    "specificIssue": "Prompt says 'Title-enhancing attributes should be ranked 1-2' but model sometimes ranks them 3rd or 4th. Model prioritizes UseCase over title attributes in some cases.",
    "expectedOutput": "Title attributes at rank 1-2",
    "actualOutput": "Title attributes at rank 3+",
    "detailedSuggestion": "PROMPT FIX: Make title priority explicit: '**RULE**: Title attributes MUST be ranked 1 or 2. No exceptions. UseCase attributes start at rank 3.'",
    "impact": "Expected to improve from 10% to 80%+",
    "validated": false,
    "module": "M08"
  },
  {
    "rubric": "Invalid M09 Output Flagged",
    "criticality": "Critical",
    "passRate": 20.0,
    "issueType": "Judge Issue (Strict Matching)",
    "analysisSummary": "CRITICAL: Judge fails because model output is semantically equivalent but not exact string match",
    "specificIssue": "Expected: 'Listening to audio'. Model: 'Wireless music and audio listening'. BOTH describe the same primary use! The judge does strict string matching instead of semantic comparison. 90% of failures are valid outputs rejected due to phrasing differences.",
    "expectedOutput": "PASS for semantically equivalent uses",
    "actualOutput": "FAIL due to string mismatch (but meaning is identical)",
    "detailedSuggestion": "RUBRIC FIX: Allow semantic equivalence in primary use comparison. Add to pass_definition: 'Semantically equivalent primary uses are acceptable. Examples of equivalent uses: \"Listening to audio\" = \"Wireless music listening\" = \"Audio playback\"'",
    "rubricChange": "Add semantic equivalence examples to M10_invalid_correctly_flagged rubric",
    "impact": "Expected to improve from 20% to 85%+ if semantic matching allowed",
    "validated": true,
    "validation_note": "Verified 9/10 failures are semantically correct but rejected due to exact match",
    "module": "M10"
  },
  {
    "rubric": "Constraints Are Product-Specific",
    "criticality": "Medium",
    "passRate": 40.0,
    "issueType": "Model Issue",
    "analysisSummary": "Model sometimes includes generic constraints instead of product-specific ones",
    "specificIssue": "For wireless earbuds, model outputs generic constraints like 'must have battery' or 'must be electronic' instead of product-specific ones like 'must have Bluetooth' or 'must fit in ear canal'.",
    "expectedOutput": "Product-specific constraints only",
    "actualOutput": "Mix of generic and specific constraints",
    "detailedSuggestion": "PROMPT FIX: Add explicit examples of what is NOT a hard constraint: 'NOT constraints: must have battery (too generic), must be electronic (too obvious), must have packaging'",
    "promptChange": "Add: '### What is NOT a hard constraint:\\n- Generic product requirements (has battery, is electronic)\\n- Obvious physical requirements (has packaging)\\n- Subjective qualities (good quality, premium feel)'",
    "impact": "Expected to improve from 40% to 70%+",
    "validated": false,
    "module": "M11"
  },
  {
    "rubric": "Taxonomy Generated",
    "criticality": "Medium",
    "passRate": 65.0,
    "issueType": "Model Issue",
    "analysisSummary": "Taxonomy sometimes too generic or misses key product types",
    "specificIssue": "For some product categories, model generates overly broad taxonomy (e.g., 'Electronics > Audio' instead of 'Electronics > Audio > Wireless Earbuds > True Wireless'). Depth requirement not always met.",
    "expectedOutput": "3-5 level taxonomy with specific product type",
    "actualOutput": "2-3 level taxonomy, too broad",
    "detailedSuggestion": "PROMPT FIX: Emphasize minimum depth requirement: 'Taxonomy MUST have at least 4 levels for consumer products. Example: Electronics > Audio > Earbuds > True Wireless > Noise Cancelling'",
    "impact": "Expected to improve from 65% to 80%+",
    "validated": false,
    "module": "M06"
  },
  {
    "rubric": "Primary Use Identified",
    "criticality": "Medium",
    "passRate": 62.5,
    "issueType": "Model Issue + Data Issue",
    "analysisSummary": "Model identifies correct use but phrasing doesn't match expected exactly",
    "specificIssue": "Similar to M10 issue - model outputs correct primary use but with different phrasing. Expected: 'For cooking food'. Actual: 'Cooking and food preparation'. Same meaning, different words.",
    "expectedOutput": "Exact match with expected phrasing",
    "actualOutput": "Semantically correct but different phrasing",
    "detailedSuggestion": "DATA FIX: Update expected values to be more flexible OR add semantic matching to judge",
    "impact": "Expected to improve from 62.5% to 85%+ with flexible matching",
    "validated": false,
    "module": "M09"
  },
  {
    "rubric": "Complementary Correctly Identified",
    "criticality": "Medium",
    "passRate": 75.0,
    "issueType": "Model Issue",
    "analysisSummary": "Some complementary relationships not identified correctly",
    "specificIssue": "Model sometimes misses complementary products (e.g., for phone case, doesn't identify screen protector as complementary) or incorrectly marks substitutes as complementary.",
    "expectedOutput": "Accurate complementary classification",
    "actualOutput": "Missing some complementary products",
    "detailedSuggestion": "PROMPT FIX: Add clear examples: 'Complementary = used TOGETHER (phone case + screen protector). Substitute = used INSTEAD OF (phone case A vs phone case B)'",
    "promptChange": "Add: '### Complementary vs Substitute\\n- Complementary: Products used TOGETHER (phone + case, laptop + mouse)\\n- Substitute: Products used INSTEAD (case A replaces case B)'",
    "impact": "Expected to improve from 75% to 90%+",
    "validated": false,
    "module": "M16"
  }
];
        const appliedData = {
  "version": "1.0",
  "last_updated": "2026-01-19",
  "prompt_versions": {
    "M01": {
      "v1": {
        "file": "m01_extract_own_brand_entities.md",
        "date": "2026-01-15",
        "description": "Initial version",
        "applied_suggestions": [],
        "baseline_pass_rate": 33.3,
        "model": "gpt-4o-mini"
      },
      "v2": {
        "file": "m01_v2_extract_own_brand_entities.md",
        "date": "2026-01-19",
        "description": "Minor example changes, same structure as v1",
        "applied_suggestions": [],
        "pass_rate": 27.0,
        "model": "gpt-4o-mini",
        "notes": "No major changes, just example updates"
      },
      "v3": {
        "file": "m01_v3_extract_own_brand_entities.md",
        "date": "2026-01-19",
        "description": "Major improvements based on evaluation feedback",
        "applied_suggestions": [
          {
            "id": "M01_SUG_001",
            "rubric": "No Hallucinated Brand",
            "suggestion_summary": "Skip ENTIRE sub-brand when last word is generic",
            "prompt_change": "Added section \"\ud83d\udeab DO NOT Extract Partial Sub-Brands\":\n- When multi-word sub-brand fails Amazon Test, skip ENTIRE concept\n- Example: \"Sound Pro\" \u2192 \"pro\" is generic \u2192 skip both words, NOT just \"Pro\"\n- Only extract main brand (e.g., \"Bose\")\n",
            "expected_impact": "60% \u2192 90%+ for No Hallucinated Brand rubric",
            "status": "APPLIED"
          },
          {
            "id": "M01_SUG_002",
            "rubric": "Brand Extracted",
            "suggestion_summary": "Handle multi-word brand names like 'Hydro Flask'",
            "prompt_change": "Added section \"Handle Multi-Word Brand Names\":\n- Extract full form: \"Hydro Flask\", \"hydro flask\"\n- Extract merged: \"HydroFlask\", \"hydroflask\"\n- Extract first word: \"Hydro\", \"hydro\"\n- Apply typos to merged and first word\n",
            "expected_impact": "Better coverage for multi-word brands",
            "status": "APPLIED"
          }
        ],
        "pass_rate": 77.3,
        "model": "gpt-5",
        "improvement_vs_baseline": "+44.0%",
        "notes": "Best version - combines prompt improvements with stronger model"
      }
    }
  },
  "pending_suggestions": {
    "M01": [
      {
        "id": "M01_SUG_003",
        "rubric": "No Product Words in Brand",
        "suggestion": "Add AirPods, iPhone, iPad to product words exclusion list",
        "status": "PROPOSED",
        "priority": "Medium"
      },
      {
        "id": "M01_SUG_004",
        "rubric": "No Duplicate Entities",
        "suggestion": "Add explicit character-by-character duplicate check instruction",
        "status": "PROPOSED",
        "priority": "Medium"
      }
    ],
    "M04": [
      {
        "id": "M04_SUG_001",
        "rubric": "Correct CB/null Classification",
        "suggestion": "Fix dataset - brands not in competitor_entities should expect null",
        "status": "DATA_FIX_NEEDED",
        "priority": "Critical",
        "affected_keywords": [
          "oven mitts oxo",
          "blue q oven mitt",
          "sur la table oven mitts",
          "pioneer woman oven mitts",
          "cuisinart oven mitts"
        ]
      }
    ]
  },
  "impact_summary": {
    "M01": {
      "baseline": 33.3,
      "current": 77.3,
      "improvement": 44.0,
      "applied_count": 2,
      "pending_count": 2
    },
    "M04": {
      "baseline": 43.3,
      "current": 60.0,
      "improvement": 16.7,
      "applied_count": 0,
      "pending_count": 1,
      "notes": "Improvement from model upgrade (gpt-4o-mini \u2192 gpt-4o), not prompt changes"
    }
  }
};
        const improvementHistory = {
  "version": "1.0",
  "last_updated": "2026-01-20",
  "modules": {
    "M01": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-19",
            "pass_rate": 30.0,
            "model": "gpt-4o-mini",
            "data_source": "M01_ExtractOwnBrandEntities_v1_150126_1.csv",
            "rubric_breakdown": {
              "Brand Extracted": "40%",
              "No Hallucinated Brand": "20%",
              "No Product Words in Brand": "30%",
              "Amazon Test Applied": "20%",
              "No Duplicate Entities": "40%"
            }
          },
          "suggestions": [
            {
              "rubric": "Brand Extracted",
              "issue": "Model misses brand variations and sub-brands",
              "suggestion": "Add explicit examples of brand extraction patterns",
              "priority": "high",
              "status": "applied",
              "applied_in": "v2"
            },
            {
              "rubric": "Amazon Test Applied",
              "issue": "Model doesn't consistently apply Amazon search test",
              "suggestion": "Add step-by-step Amazon Test instructions",
              "priority": "high",
              "status": "applied",
              "applied_in": "v2"
            }
          ]
        },
        "v2": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 45.0,
            "model": "gpt-4o",
            "data_source": "M01_ExtractOwnBrandEntities_v2_190126_1.csv",
            "rubric_breakdown": {
              "Brand Extracted": "60%",
              "No Hallucinated Brand": "50%",
              "No Product Words in Brand": "40%",
              "Amazon Test Applied": "30%",
              "No Duplicate Entities": "45%"
            }
          },
          "applied_from_v1": [
            "Added explicit examples of brand extraction patterns",
            "Added step-by-step Amazon Test instructions"
          ],
          "improvement_vs_previous": "+15%",
          "suggestions": [
            {
              "rubric": "No Hallucinated Brand",
              "issue": "Model extracts sub-brand parts separately (Vibe from Vibe Beam)",
              "suggestion": "Add rule: if sub-brand fails Amazon Test, skip ENTIRE sub-brand",
              "priority": "high",
              "status": "applied",
              "applied_in": "v3"
            },
            {
              "rubric": "No Product Words in Brand",
              "issue": "AirPods extracted as brand instead of product word",
              "suggestion": "Add AirPods, iPhone, iPad to product words exclusion list",
              "priority": "medium",
              "status": "applied",
              "applied_in": "v3"
            }
          ]
        },
        "v3": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 70.0,
            "model": "gpt-4o-mini",
            "data_source": "M01_V2_ExtractOwnBrandEntities_v3_190126_1.csv",
            "rubric_breakdown": {
              "Brand Extracted": "70%",
              "No Hallucinated Brand": "40%",
              "No Product Words in Brand": "90%",
              "Amazon Test Applied": "70%",
              "No Duplicate Entities": "80%"
            }
          },
          "applied_from_v2": [
            "Added rule: skip entire sub-brand if fails Amazon Test",
            "Added Apple products to exclusion list"
          ],
          "improvement_vs_previous": "+25%",
          "suggestions": [
            {
              "rubric": "No Hallucinated Brand",
              "issue": "Still extracting partial sub-brands in some cases",
              "suggestion": "Add more examples of sub-brand handling in prompt",
              "priority": "high",
              "status": "pending"
            },
            {
              "rubric": "No Duplicate Entities",
              "issue": "Some duplicate variations appearing",
              "suggestion": "Add deduplication step before output",
              "priority": "medium",
              "status": "pending"
            }
          ]
        },
        "v3_gpt5": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 60.0,
            "model": "gpt-5",
            "data_source": "M01_V3_ExtractOwnBrandEntities_v3_190126_gpt5.csv",
            "rubric_breakdown": {
              "Brand Extracted": "40%",
              "No Hallucinated Brand": "40%",
              "No Product Words in Brand": "70%",
              "Amazon Test Applied": "50%",
              "No Duplicate Entities": "100%"
            }
          },
          "note": "Same v3 prompt tested with gpt-5. Lower performance except No Duplicate Entities.",
          "suggestions": [
            {
              "rubric": "Brand Extracted",
              "issue": "GPT-5 more conservative, misses valid brands",
              "suggestion": "Prompt may need adjustment for gpt-5 behavior",
              "priority": "medium",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M01A": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-19",
            "pass_rate": 90.0,
            "model": "gpt-4o-mini",
            "data_source": "M01A_ExtractOwnBrandVariations_v1_150126_1.csv"
          },
          "suggestions": [
            {
              "rubric": "Variations Generated",
              "issue": "Some edge cases missed",
              "suggestion": "Add more typo patterns",
              "priority": "low",
              "status": "applied",
              "applied_in": "v2"
            }
          ]
        },
        "v2": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 85.0,
            "model": "gpt-5",
            "data_source": "M01A_V2_ExtractOwnBrandVariations_v2_190126_gpt5.csv"
          },
          "applied_from_v1": [
            "Added more typo patterns"
          ],
          "improvement_vs_previous": "-5%",
          "note": "Regression with gpt-5, may need prompt adjustment",
          "suggestions": [
            {
              "rubric": "No Duplicates",
              "issue": "GPT-5 generates some duplicates",
              "suggestion": "Add explicit deduplication instruction",
              "priority": "medium",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M04": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-19",
            "pass_rate": 60.0,
            "model": "gpt-4o",
            "data_source": "M04_ClassifyCompetitorBrandKeywords_v1_150126_1.csv",
            "rubric_breakdown": {
              "Correct CB/null Classification": "33%",
              "Case Insensitive Matching": "40%",
              "Competitor Correctly Identified": "67%",
              "Own Brand Excluded": "100%"
            }
          },
          "suggestions": [
            {
              "rubric": "Correct CB/null Classification",
              "issue": "DATA ISSUE: Expected='CB' but brand NOT in competitor_entities list",
              "suggestion": "Fix dataset: change expected from 'CB' to null for OXO, Blue Q, Sur La Table, etc.",
              "priority": "high",
              "status": "pending"
            },
            {
              "rubric": "Case Insensitive Matching",
              "issue": "Same DATA ISSUE causing failures",
              "suggestion": "Update expected values for brands not in competitor list",
              "priority": "high",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M06": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 65.0,
            "model": "gpt-4o-mini",
            "data_source": "M06_GenerateProductTypeTaxonomy_gd1_v1_150126_1.csv"
          },
          "suggestions": [
            {
              "rubric": "Taxonomy Generated",
              "issue": "Taxonomy sometimes too generic, misses depth requirement",
              "suggestion": "Emphasize minimum 4-level depth for consumer products",
              "priority": "medium",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M08": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 5.0,
            "model": "gpt-4o",
            "data_source": "M08_AssignAttributeRanks_v1_150126_1.csv",
            "rubric_breakdown": {
              "Ranks Assigned": "5%",
              "Title Attributes Ranked 1-2": "10%",
              "Unique Ranks Per Type": "15%"
            }
          },
          "suggestions": [
            {
              "rubric": "Ranks Assigned",
              "issue": "PROMPT/SCHEMA MISMATCH: Prompt had 'UseCase' but expected data has 'Use Case' (with space)",
              "suggestion": "Fixed prompts and JSON schemas to use 'Use Case'",
              "priority": "high",
              "status": "applied",
              "applied_date": "2026-01-20",
              "fix_details": "Changed UseCase â†’ Use Case in: m08_assign_attribute_ranks.md, m08_v2_assign_attribute_ranks.md, m08_assign_attribute_ranks_v2.md, and both JSON schemas"
            },
            {
              "rubric": "Ranks Assigned",
              "issue": "MODEL ISSUE: Model doesn't rank ALL attributes (skips some)",
              "suggestion": "Add instruction: 'Rank EVERY attribute. If N attributes, output ranks 1-N'",
              "priority": "high",
              "status": "pending"
            },
            {
              "rubric": "Title Attributes Ranked 1-2",
              "issue": "Title attributes sometimes ranked 3+ instead of 1-2",
              "suggestion": "Make title priority explicit in prompt",
              "priority": "medium",
              "status": "pending"
            }
          ],
          "note": "m08_sd REMOVED - contained M07 data (invalid dataset)"
        },
        "v2": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 7.5,
            "model": "gpt-4o",
            "data_source": "M08_V2_AssignAttributeRanks_v1_150126_1.csv",
            "rubric_breakdown": {
              "Ranks Assigned": "8%",
              "Title Attributes Ranked 1-2": "10%",
              "Unique Ranks Per Type": "12%"
            }
          },
          "applied_from_v1": [
            "Changed to Pairwise Comparison Method (wins/losses)",
            "Fixed UseCase â†’ Use Case spelling mismatch (2026-01-20)"
          ],
          "improvement_vs_previous": "+2.5%",
          "suggestions": [
            {
              "rubric": "Ranks Assigned",
              "issue": "MODEL ISSUE: Model skips Use Case attributes entirely",
              "suggestion": "Add explicit reminder: 'Include ALL attribute types: Variant, Use Case, Audience'",
              "priority": "high",
              "status": "pending"
            },
            {
              "rubric": "Ranks Assigned",
              "issue": "MODEL ISSUE: Model drops some Variant attributes (e.g., 'White')",
              "suggestion": "Add instruction: 'Every input attribute MUST appear in output'",
              "priority": "high",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M09": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 62.5,
            "model": "gpt-4o-mini",
            "data_source": "M09_IdentifyPrimaryIntendedUse_v1_150126_1.csv"
          },
          "suggestions": [
            {
              "rubric": "Primary Use Identified",
              "issue": "Model identifies correct use but phrasing doesn't match expected",
              "suggestion": "Allow semantic equivalence or update expected values",
              "priority": "medium",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M10": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 20.0,
            "model": "gpt-4o-mini",
            "data_source": "M10_ValidatePrimaryIntendedUse_v1_150126_1.csv",
            "rubric_breakdown": {
              "Invalid M09 Output Flagged": "20%",
              "Fix Improves Output": "40%"
            }
          },
          "suggestions": [
            {
              "rubric": "Invalid M09 Output Flagged",
              "issue": "JUDGE ISSUE: Strict string matching instead of semantic equivalence",
              "suggestion": "Allow semantic matching: 'Listening to audio' = 'Wireless music listening'",
              "priority": "high",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M11": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 52.9,
            "model": "gpt-4o-mini",
            "data_source": "M11_IdentifyHardConstraints_v1_150126_1.csv"
          },
          "suggestions": [
            {
              "rubric": "Constraints Are Product-Specific",
              "issue": "Model includes generic constraints (must have battery, must be electronic)",
              "suggestion": "Add examples of what is NOT a hard constraint",
              "priority": "medium",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M16": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 75.0,
            "model": "gpt-4o-mini",
            "data_source": "M16_ComplementaryCheck_v1_150126_1.csv"
          },
          "suggestions": [
            {
              "rubric": "Complementary Correctly Identified",
              "issue": "Some complementary relationships missed or confused with substitutes",
              "suggestion": "Add clear examples: Complementary=used TOGETHER, Substitute=used INSTEAD",
              "priority": "medium",
              "status": "pending"
            }
          ]
        }
      }
    },
    "M02": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-19",
            "pass_rate": 100.0,
            "model": "gpt-4o-mini",
            "data_source": "M02_ClassifyOwnBrandKeywords_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    },
    "M05": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 100.0,
            "model": "gpt-4o-mini",
            "data_source": "M05_ClassifyNonBrandedKeywords_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    },
    "M07": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 75.0,
            "model": "gpt-4o-mini",
            "data_source": "M07_ExtractProductAttributes_gd1_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    },
    "M12": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 60.0,
            "model": "gpt-4o-mini",
            "data_source": "M12_HardConstraintViolationCheck_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    },
    "M13": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 90.0,
            "model": "gpt-4o-mini",
            "data_source": "M13_ProductTypeCheck_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    },
    "M14": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 100.0,
            "model": "gpt-4o-mini",
            "data_source": "M14_PrimaryUseCheckSameType_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    },
    "M15": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-20",
            "pass_rate": 95.0,
            "model": "gpt-4o-mini",
            "data_source": "M15_SubstituteCheck_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    },
    "M01B": {
      "versions": {
        "v1": {
          "evaluation": {
            "date": "2026-01-19",
            "pass_rate": 73.3,
            "model": "gpt-4o-mini",
            "data_source": "M01B_ExtractBrandRelatedTerms_v1_150126_1.csv"
          },
          "suggestions": []
        }
      }
    }
  }
};

        let passRateChart = null;
        let modelCompareChart = null;

        // Map module to folder (based on MODULE_CSV_MAP structure)
        const MODULE_FOLDER_MAP = {
            'm01_v1': 'M01_ExtractOwnBrandEntities',
            'm01_v2': 'M01_ExtractOwnBrandEntities',
            'm01_v3': 'M01_ExtractOwnBrandEntities',
            'm01a': 'M01A_ExtractOwnBrandVariations_PathB',
            'm01a_v2': 'M01A_ExtractOwnBrandVariations_PathB',
            'm01b': 'M01B_ExtractBrandRelatedTerms_PathB',
            'm02': 'M02_ClassifyOwnBrandKeywords',
            'm02b': 'M02B_ClassifyOwnBrandKeywords_PathB',
            'm04': 'M04_ClassifyCompetitorBrandKeywords',
            'm04b': 'M04B_ClassifyCompetitorBrandKeywords_PathB',
            'm05': 'M05_ClassifyNonBrandedKeywords',
            'm05b': 'M05B_ClassifyNonBrandedKeywords_PathB',
            'm06_gd': 'M06_GenerateProductTypeTaxonomy',
            'm06_sd': 'M06_GenerateProductTypeTaxonomy',
            'm07_gd': 'M07_ExtractProductAttributes',
            'm07_sd': 'M07_ExtractProductAttributes',
            'm08': 'M08_AssignAttributeRanks',
            'm08_v2': 'M08_AssignAttributeRanks',
            'm08_v2_sd': 'M08_AssignAttributeRanks',
            'm09': 'M09_IdentifyPrimaryIntendedUse',
            'm10': 'M10_ValidatePrimaryIntendedUse',
            'm11': 'M11_IdentifyHardConstraints',
            'm12': 'M12_HardConstraintViolationCheck',
            'm13': 'M13_ProductTypeCheck',
            'm14': 'M14_PrimaryUseCheckSameType',
            'm15': 'M15_SubstituteCheck',
            'm16': 'M16_ComplementaryCheck',
        };

        // Get folder for a module
        function getModuleFolder(module) {
            return MODULE_FOLDER_MAP[module.toLowerCase()] || module.toUpperCase();
        }

        // Get short name for folder (e.g., "M01_ExtractOwnBrandEntities" -> "M01")
        function getFolderShortName(folder) {
            const match = folder.match(/^(M\d+[A-B]?)_/);
            return match ? match[1] : folder;
        }

        // Get all unique folders with natural sort (M01, M01A, M01B, M02, M02B, ...)
        const folders = [...new Set(progressData.map(r => getModuleFolder(r.module)))].sort((a, b) => {
            // Extract module number and optional letter suffix
            const matchA = a.match(/^M(\d+)([A-B])?_/);
            const matchB = b.match(/^M(\d+)([A-B])?_/);
            if (!matchA || !matchB) return a.localeCompare(b);

            const numA = parseInt(matchA[1]);
            const numB = parseInt(matchB[1]);
            if (numA !== numB) return numA - numB;

            // Same number - base module (no letter) comes first
            const letterA = matchA[2] || '';
            const letterB = matchB[2] || '';
            return letterA.localeCompare(letterB);
        });

        // Map folder -> list of modules
        const folderModules = {};
        progressData.forEach(r => {
            const folder = getModuleFolder(r.module);
            if (!folderModules[folder]) folderModules[folder] = new Set();
            folderModules[folder].add(r.module);
        });

        function initModuleSelector() {
            const container = document.getElementById('moduleSelector');
            folders.forEach((folder, idx) => {
                const btn = document.createElement('button');
                const moduleCount = folderModules[folder].size;
                const shortName = getFolderShortName(folder);
                btn.className = 'module-btn' + (idx === 0 ? ' active' : '');
                btn.textContent = shortName + (moduleCount > 1 ? ` (${moduleCount})` : '');
                btn.title = folder; // Full name on hover
                btn.dataset.folder = folder;
                btn.onclick = () => selectFolder(folder);
                container.appendChild(btn);
            });
        }

        function selectFolder(folder) {
            document.querySelectorAll('.module-btn').forEach(btn => {
                btn.classList.toggle('active', btn.dataset.folder === folder);
            });

            // Get all runs from modules in this folder
            const moduleRuns = progressData.filter(r => getModuleFolder(r.module) === folder);
            // Sort: _v1 (baseline) first, then _v2, then base module (latest) last
            moduleRuns.sort((a, b) => {
                // Extract version from module name suffix (_v1 -> 1, _v2 -> 2, no suffix -> 999 = latest)
                const getModuleVersion = (mod) => {
                    const match = mod.match(/_v(\d+)$/i);
                    return match ? parseInt(match[1]) : 999; // no suffix = latest
                };
                const verA = getModuleVersion(a.module);
                const verB = getModuleVersion(b.module);
                if (verA !== verB) return verA - verB;
                // Same version - sort by module name
                return a.module.localeCompare(b.module);
            });

            updateStats(moduleRuns);
            updatePassRateChart(moduleRuns);
            updateModelCompareChart(moduleRuns);
            updateProgressTable(moduleRuns);
            updateAppliedImprovements(folder, moduleRuns);
            updateSuggestions(folder, moduleRuns);
        }

        function updateStats(runs) {
            if (runs.length === 0) return;
            const latest = runs[runs.length - 1];
            const first = runs[0];
            const improvement = latest.pass_rate - first.pass_rate;
            const improvementClass = improvement > 0 ? 'green' : improvement < 0 ? 'red' : 'yellow';

            document.getElementById('statsGrid').innerHTML = `
                <div class="stat-card">
                    <div class="stat-value blue">${latest.pass_rate.toFixed(1)}%</div>
                    <div class="stat-label">Current Pass Rate</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value ${improvementClass}">${improvement >= 0 ? '+' : ''}${improvement.toFixed(1)}%</div>
                    <div class="stat-label">Improvement</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value green">${latest.summary?.pass || 0}</div>
                    <div class="stat-label">Passing Tests</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value red">${latest.summary?.fail || 0}</div>
                    <div class="stat-label">Failing Tests</div>
                </div>
            `;
        }

        function updatePassRateChart(runs) {
            const ctx = document.getElementById('passRateChart').getContext('2d');
            // Sort by prompt_version: v1 first (left), v2, v3 last (right) for progression
            const getPromptVersion = (run) => {
                const match = run.prompt_version?.match(/v(\d+)/i);
                return match ? parseInt(match[1]) : 0;
            };
            const sortedRuns = [...runs].sort((a, b) => {
                const verA = getPromptVersion(a);
                const verB = getPromptVersion(b);
                if (verA !== verB) return verA - verB; // v1 < v2 < v3 (ascending for chart)
                return (a.model || '').localeCompare(b.model || '');
            });
            // Include module name in label for clarity, show full model name
            const labels = sortedRuns.map(r => `${r.prompt_version} (${r.model})`);
            const passRates = sortedRuns.map(r => r.pass_rate);
            const matchRates = sortedRuns.map(r => r.match_rate || 0);

            if (passRateChart) passRateChart.destroy();

            passRateChart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: labels,
                    datasets: [
                        { label: 'Pass Rate %', data: passRates, borderColor: '#3b82f6', backgroundColor: 'rgba(59, 130, 246, 0.1)', fill: true, tension: 0.3, pointRadius: 6 },
                        { label: 'Match Rate %', data: matchRates, borderColor: '#22c55e', backgroundColor: 'rgba(34, 197, 94, 0.1)', fill: true, tension: 0.3, pointRadius: 6 }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: { legend: { labels: { color: '#94a3b8' } } },
                    scales: {
                        y: { beginAtZero: true, max: 100, grid: { color: '#334155' }, ticks: { color: '#94a3b8' } },
                        x: { grid: { color: '#334155' }, ticks: { color: '#94a3b8' } }
                    }
                }
            });
        }

        function updateModelCompareChart(runs) {
            const ctx = document.getElementById('modelCompareChart').getContext('2d');
            const modelGroups = {};
            runs.forEach(r => {
                if (!modelGroups[r.model]) modelGroups[r.model] = [];
                modelGroups[r.model].push(r);
            });

            const labels = Object.keys(modelGroups);
            const avgPassRates = labels.map(model => {
                const modelRuns = modelGroups[model];
                return modelRuns.reduce((sum, r) => sum + r.pass_rate, 0) / modelRuns.length;
            });

            if (modelCompareChart) modelCompareChart.destroy();

            modelCompareChart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: labels,
                    datasets: [{
                        label: 'Avg Pass Rate %',
                        data: avgPassRates,
                        backgroundColor: labels.map(l => l.includes('gpt-5') ? '#a855f7' : l.includes('gpt-4o-mini') ? '#60a5fa' : '#22c55e'),
                        borderRadius: 6
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: { legend: { display: false } },
                    scales: {
                        y: { beginAtZero: true, max: 100, grid: { color: '#334155' }, ticks: { color: '#94a3b8' } },
                        x: { grid: { display: false }, ticks: { color: '#94a3b8' } }
                    }
                }
            });
        }

        function updateProgressTable(runs) {
            const tbody = document.querySelector('#progressTable tbody');
            tbody.innerHTML = '';
            // Sort by prompt_version field: latest (v3) at TOP, baseline (v1) at BOTTOM
            const sortedRuns = [...runs].sort((a, b) => {
                const getPromptVersion = (run) => {
                    const match = run.prompt_version?.match(/v(\d+)/i);
                    return match ? parseInt(match[1]) : 0;
                };
                const verA = getPromptVersion(a);
                const verB = getPromptVersion(b);
                if (verA !== verB) return verB - verA; // Higher version first (v3 > v2 > v1)
                // Same prompt version - sort by model name
                return (a.model || '').localeCompare(b.model || '');
            });

            sortedRuns.forEach((run, idx) => {
                let trend = '';
                if (idx === sortedRuns.length - 1) {
                    // Last row (v1) is baseline
                    trend = `<span class="trend-indicator trend-same">baseline</span>`;
                } else {
                    // Compare to NEXT row (older version) to show progress
                    const prev = sortedRuns[idx + 1];
                    const diff = run.pass_rate - prev.pass_rate;
                    if (diff > 0) trend = `<span class="trend-indicator trend-up">â–² +${diff.toFixed(1)}%</span>`;
                    else if (diff < 0) trend = `<span class="trend-indicator trend-down">â–¼ ${diff.toFixed(1)}%</span>`;
                    else trend = `<span class="trend-indicator trend-same">â€” 0%</span>`;
                }

                const passRateColor = run.pass_rate >= 80 ? '#22c55e' : run.pass_rate >= 60 ? '#eab308' : run.pass_rate >= 40 ? '#f97316' : '#ef4444';

                const row = document.createElement('tr');

                // Format dataset name (truncate if needed)
                const datasetName = run.dataset_name || 'N/A';
                const shortDataset = datasetName.length > 25 ? datasetName.slice(0, 22) + '...' : datasetName;

                // Braintrust link - use experiment name URL-encoded with correct org/project
                const btLink = run.braintrust_name
                    ? `<a href="https://www.braintrust.dev/app/KCC/p/Keyword-Classification-Pipeline-V1.1/experiments/${encodeURIComponent(run.braintrust_name)}" target="_blank" style="color: var(--accent-blue); font-size: 0.75rem; text-decoration: none;">View â†—</a>`
                    : '<span style="color: var(--text-secondary); font-size: 0.75rem;">â€”</span>';

                row.innerHTML = `
                    <td><span class="module-badge" style="background: #334155; padding: 2px 8px; border-radius: 4px; font-size: 0.75rem; font-weight: 600;">${run.module.toUpperCase()}</span></td>
                    <td><span class="version-badge ${run.prompt_version}">${run.prompt_version}</span></td>
                    <td><span class="model-badge">${run.model}</span></td>
                    <td title="${datasetName}&#10;ID: ${run.dataset_id || 'N/A'}" style="font-size: 0.75rem; color: var(--text-secondary); max-width: 150px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;">${shortDataset}</td>
                    <td>
                        <div style="display: flex; align-items: center; gap: 10px;">
                            <span style="width: 50px; font-weight: 600; color: ${passRateColor}">${run.pass_rate.toFixed(1)}%</span>
                            <div class="rate-bar" style="flex: 1; max-width: 80px;">
                                <div class="rate-bar-fill" style="width: ${run.pass_rate}%; background: ${passRateColor}"></div>
                            </div>
                        </div>
                    </td>
                    <td>${(run.match_rate || 0).toFixed(1)}%</td>
                    <td><span style="color: #22c55e">${run.summary?.pass || 0}</span> / <span style="color: #ef4444">${run.summary?.fail || 0}</span></td>
                    <td>${trend}</td>
                    <td>${btLink}</td>
                `;
                tbody.appendChild(row);
            });
        }

        function updateAppliedImprovements(family, moduleRuns) {
            const container = document.getElementById('appliedImprovements');

            // Get all unique modules in this family from the runs
            const modulesInFamily = [...new Set(moduleRuns.map(r => r.module.toUpperCase()))];

            // Collect version info from all modules in the family
            let allVersionCards = [];

            modulesInFamily.forEach(moduleKey => {
                const versions = appliedData.prompt_versions?.[moduleKey] || {};

                Object.keys(versions).forEach(ver => {
                    const v = versions[ver];
                    const applied = v.applied_suggestions || [];
                    const hasImprovements = applied.length > 0;

                    allVersionCards.push({
                        module: moduleKey,
                        version: ver,
                        data: v,
                        applied: applied,
                        hasImprovements: hasImprovements
                    });
                });
            });

            if (allVersionCards.length === 0) {
                container.innerHTML = '<p class="no-improvements">No version history available for this module family.</p>';
                return;
            }

            // Sort by version descending
            allVersionCards.sort((a, b) => b.version.localeCompare(a.version));

            container.innerHTML = allVersionCards.map(card => {
                const v = card.data;
                const applied = card.applied;
                const hasImprovements = card.hasImprovements;

                return `
                    <div class="version-card ${hasImprovements ? 'has-improvements' : ''}">
                        <div class="version-header">
                            <span class="version-title">
                                <span class="module-badge" style="background: #334155; padding: 2px 8px; border-radius: 4px; font-size: 0.75rem; font-weight: 600; margin-right: 6px;">${card.module}</span>
                                <span class="version-badge ${card.version}">${card.version}</span>
                                ${v.file || ''}
                            </span>
                            <span class="version-meta">
                                ${v.model || ''} | ${v.pass_rate ? v.pass_rate + '%' : ''} | ${v.date || ''}
                            </span>
                        </div>
                        <p style="color: var(--text-secondary); font-size: 0.85rem; margin-bottom: 10px;">${v.description || ''}</p>
                        ${hasImprovements ? `
                            <div style="margin-top: 10px;">
                                <strong style="color: var(--accent-green); font-size: 0.85rem;">âœ“ Applied Improvements:</strong>
                                ${applied.map(imp => `
                                    <div class="improvement-item">
                                        <span class="rubric">${imp.rubric}</span>
                                        <span class="suggestion-status applied">${imp.status}</span>
                                        <div class="change">${imp.suggestion_summary}</div>
                                    </div>
                                `).join('')}
                            </div>
                        ` : '<p class="no-improvements">No improvements applied in this version</p>'}
                    </div>
                `;
            }).join('');
        }

        function updateSuggestions(family, moduleRuns) {
            const container = document.getElementById('suggestionsList');

            // Get module key from folder name (e.g., M01_ExtractOwnBrandEntities -> M01)
            const moduleKey = family.split('_')[0];
            console.log('[DEBUG] updateSuggestions:', family, '->', moduleKey);
            const moduleHistory = improvementHistory.modules?.[moduleKey];
            console.log('[DEBUG] moduleHistory found:', !!moduleHistory, moduleHistory?.versions ? Object.keys(moduleHistory.versions) : []);

            if (!moduleHistory || !moduleHistory.versions) {
                container.innerHTML = '<li class="no-improvements">No improvement history available for this module.</li>';
                return;
            }

            // Build version-based suggestions display
            const versions = Object.entries(moduleHistory.versions);
            let html = '';

            versions.forEach(([versionId, versionData]) => {
                const suggestions = versionData.suggestions || [];
                const appliedFrom = versionData.applied_from_v1 || versionData.applied_from_v2 || versionData.applied_from_v3 || [];
                const evaluation = versionData.evaluation || {};
                const improvement = versionData.improvement_vs_previous || '';

                const pendingSuggestions = suggestions.filter(s => s.status === 'pending');
                const appliedSuggestions = suggestions.filter(s => s.status === 'applied');

                html += `
                    <div style="margin-bottom: 20px; padding: 15px; background: #1e293b; border-radius: 8px; border-left: 3px solid ${pendingSuggestions.length > 0 ? '#f59e0b' : '#22c55e'};">
                        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                            <div>
                                <span class="version-badge ${versionId}" style="font-size: 0.9rem;">${versionId.toUpperCase()}</span>
                                <span style="margin-left: 10px; color: #94a3b8;">${evaluation.model || ''}</span>
                                <span style="margin-left: 10px; font-weight: bold; color: ${evaluation.pass_rate >= 70 ? '#22c55e' : evaluation.pass_rate >= 50 ? '#f59e0b' : '#ef4444'};">
                                    ${evaluation.pass_rate || 0}%
                                </span>
                                ${improvement ? `<span style="margin-left: 10px; color: ${improvement.startsWith('+') ? '#22c55e' : '#ef4444'};">${improvement}</span>` : ''}
                            </div>
                            <span style="font-size: 0.75rem; color: #64748b;">${evaluation.date || ''}</span>
                        </div>

                        ${appliedFrom.length > 0 ? `
                            <div style="margin-bottom: 10px; padding: 8px; background: rgba(34, 197, 94, 0.1); border-radius: 4px;">
                                <span style="color: #22c55e; font-size: 0.8rem; font-weight: 600;">âœ“ Applied in this version:</span>
                                <ul style="margin: 5px 0 0 20px; color: #94a3b8; font-size: 0.85rem;">
                                    ${appliedFrom.map(a => `<li>${a}</li>`).join('')}
                                </ul>
                            </div>
                        ` : ''}

                        ${suggestions.length > 0 ? `
                            <div style="margin-top: 10px;">
                                <span style="color: #f59e0b; font-size: 0.8rem; font-weight: 600;">
                                    ${pendingSuggestions.length > 0 ? 'âš  Suggestions for next version:' : 'âœ“ All suggestions applied'}
                                </span>
                                <ul style="margin: 8px 0 0 0; padding: 0; list-style: none;">
                                    ${suggestions.map(s => `
                                        <li style="padding: 8px; margin-top: 6px; background: #0f172a; border-radius: 4px; border-left: 2px solid ${s.status === 'pending' ? '#f59e0b' : '#22c55e'};">
                                            <div style="display: flex; justify-content: space-between; align-items: center;">
                                                <strong style="color: #e2e8f0;">${s.rubric}</strong>
                                                <div>
                                                    <span style="font-size: 0.7rem; padding: 2px 6px; border-radius: 3px; background: ${s.priority === 'high' ? '#dc2626' : s.priority === 'medium' ? '#d97706' : '#059669'}; color: white;">
                                                        ${s.priority || 'medium'}
                                                    </span>
                                                    <span style="margin-left: 6px; font-size: 0.7rem; padding: 2px 6px; border-radius: 3px; background: ${s.status === 'pending' ? '#d97706' : '#059669'}; color: white;">
                                                        ${s.status}${s.applied_in ? ' â†’ ' + s.applied_in : ''}
                                                    </span>
                                                </div>
                                            </div>
                                            <p style="margin: 6px 0 0 0; color: #94a3b8; font-size: 0.85rem;">${s.issue}</p>
                                            <p style="margin: 4px 0 0 0; color: #60a5fa; font-size: 0.85rem;">â†’ ${s.suggestion}</p>
                                            ${s.result ? `<p style="margin: 4px 0 0 0; color: #22c55e; font-size: 0.8rem;">Result: ${s.result}</p>` : ''}
                                        </li>
                                    `).join('')}
                                </ul>
                            </div>
                        ` : '<p style="color: #64748b; font-size: 0.85rem; margin-top: 10px;">No suggestions recorded for this version.</p>'}
                    </div>
                `;
            });

            container.innerHTML = html || '<li class="no-improvements">No improvement history available.</li>';
        }

        // =====================================================================
        // MODEL COST MATRIX DATA
        // =====================================================================
        // Available models via API keys (OpenAI + Gemini)
        const availableModels = [
            // OpenAI Models
            { name: 'GPT-4o', provider: 'openai', id: 'gpt-4o', input: 2.50, output: 10.00, quality: 95, speed: 85, tier: 'flagship' },
            { name: 'GPT-4o-mini', provider: 'openai', id: 'gpt-4o-mini', input: 0.15, output: 0.60, quality: 85, speed: 95, tier: 'efficient' },
            { name: 'GPT-5', provider: 'openai', id: 'gpt-5', input: 10.00, output: 30.00, quality: 98, speed: 70, tier: 'flagship' },
            { name: 'o1', provider: 'openai', id: 'o1', input: 15.00, output: 60.00, quality: 99, speed: 50, tier: 'reasoning' },
            { name: 'o1-mini', provider: 'openai', id: 'o1-mini', input: 3.00, output: 12.00, quality: 92, speed: 65, tier: 'reasoning' },
            { name: 'o3-mini', provider: 'openai', id: 'o3-mini', input: 1.10, output: 4.40, quality: 90, speed: 75, tier: 'reasoning' },
            // Google Gemini Models
            { name: 'Gemini 2.0 Flash', provider: 'google', id: 'gemini-2.0-flash', input: 0.10, output: 0.40, quality: 82, speed: 98, tier: 'efficient' },
            { name: 'Gemini 1.5 Pro', provider: 'google', id: 'gemini-1.5-pro', input: 1.25, output: 5.00, quality: 88, speed: 80, tier: 'flagship' },
            { name: 'Gemini 1.5 Flash', provider: 'google', id: 'gemini-1.5-flash', input: 0.075, output: 0.30, quality: 80, speed: 95, tier: 'efficient' },
            { name: 'Gemini 2.5 Pro', provider: 'google', id: 'gemini-2.5-pro-exp', input: 2.50, output: 10.00, quality: 92, speed: 78, tier: 'flagship' },
        ];

        // Module type configurations for recommendations
        const moduleTypeConfigs = {
            'extraction': {
                description: 'Entity extraction from text',
                recommended: ['gpt-4o-mini', 'gemini-2.0-flash', 'gpt-4o'],
                avgInputTokens: 1200, avgOutputTokens: 400,
                needs: 'Accuracy over speed'
            },
            'generation': {
                description: 'Creative text generation',
                recommended: ['gpt-4o', 'gemini-1.5-pro', 'gpt-5'],
                avgInputTokens: 800, avgOutputTokens: 600,
                needs: 'Quality & creativity'
            },
            'binary_classifier': {
                description: 'Yes/No classification',
                recommended: ['gpt-4o-mini', 'gemini-2.0-flash', 'gemini-1.5-flash'],
                avgInputTokens: 1500, avgOutputTokens: 100,
                needs: 'Speed & cost efficiency'
            },
            'classifier': {
                description: 'Multi-class classification',
                recommended: ['gpt-4o-mini', 'gemini-2.0-flash', 'gpt-4o'],
                avgInputTokens: 1800, avgOutputTokens: 150,
                needs: 'Balance of speed & accuracy'
            },
            'ranking': {
                description: 'Order/rank items',
                recommended: ['gpt-4o', 'o3-mini', 'gpt-5'],
                avgInputTokens: 2000, avgOutputTokens: 500,
                needs: 'Reasoning capability'
            },
            'validation': {
                description: 'Validate previous outputs',
                recommended: ['gpt-4o-mini', 'gemini-2.0-flash'],
                avgInputTokens: 2500, avgOutputTokens: 200,
                needs: 'Cost efficiency'
            }
        };

        // Get module type from resource mappings
        const moduleTypes = {
            'm01': 'extraction', 'm01_v1': 'extraction', 'm01_v2': 'extraction', 'm01_v3': 'extraction',
            'm01a': 'generation', 'm01a_v2': 'generation',
            'm01b': 'extraction',
            'm02': 'binary_classifier', 'm02b': 'binary_classifier',
            'm03': 'extraction',
            'm04': 'binary_classifier', 'm04b': 'binary_classifier',
            'm05': 'binary_classifier', 'm05b': 'binary_classifier',
            'm06': 'extraction', 'm06_gd': 'extraction', 'm06_sd': 'extraction',
            'm07': 'extraction', 'm07_gd': 'extraction', 'm07_sd': 'extraction',
            'm08': 'ranking', 'm08_v2': 'ranking', 'm08_v2_sd': 'ranking',
            'm09': 'extraction',
            'm10': 'validation',
            'm11': 'extraction',
            'm12': 'classifier',
            'm13': 'classifier',
            'm14': 'classifier',
            'm15': 'classifier',
            'm16': 'classifier'
        };

        // Dataset record counts from resource_mappings.yaml
        const datasetRecords = {
            'm01': 50, 'm01_v1': 50, 'm01_v2': 50, 'm01_v3': 50,
            'm01a': 50, 'm01a_v2': 50,
            'm01b': 50,
            'm02': 1000, 'm02b': 1000,
            'm04': 4700, 'm04b': 4700,
            'm05': 4700, 'm05b': 4700,
            'm06': 30, 'm06_gd': 30, 'm06_sd': 100,
            'm07': 30, 'm07_gd': 30, 'm07_sd': 100,
            'm08': 30, 'm08_v2': 30, 'm08_v2_sd': 100,
            'm09': 100,
            'm10': 100,
            'm11': 100,
            'm12': 4000,
            'm13': 4000,
            'm14': 2000,
            'm15': 1800,
            'm16': 1500
        };

        function updateModelCostMatrix(folder, moduleRuns) {
            // Get representative module for this folder
            const sampleModule = moduleRuns[0]?.module || folder.split('_')[0].toLowerCase();
            const moduleType = moduleTypes[sampleModule] || 'extraction';
            const typeConfig = moduleTypeConfigs[moduleType] || moduleTypeConfigs['extraction'];

            // Get dataset size
            const datasetSize = datasetRecords[sampleModule] || 50;
            const avgInputTokens = typeConfig.avgInputTokens;
            const avgOutputTokens = typeConfig.avgOutputTokens;

            // Update module type info
            document.getElementById('moduleTypeInfo').innerHTML = `
                <div class="type-item">
                    <span class="type-label">Module Type</span>
                    <span class="type-value">${moduleType.replace('_', ' ').toUpperCase()}</span>
                </div>
                <div class="type-item">
                    <span class="type-label">Task</span>
                    <span class="type-value">${typeConfig.description}</span>
                </div>
                <div class="type-item">
                    <span class="type-label">Priority</span>
                    <span class="type-value">${typeConfig.needs}</span>
                </div>
            `;

            // Update dataset stats
            document.getElementById('datasetStats').innerHTML = `
                <div class="dataset-stat">
                    <div class="dataset-stat-value">${datasetSize.toLocaleString()}</div>
                    <div class="dataset-stat-label">Records</div>
                </div>
                <div class="dataset-stat">
                    <div class="dataset-stat-value">~${(datasetSize * avgInputTokens / 1000).toFixed(0)}K</div>
                    <div class="dataset-stat-label">Input Tokens</div>
                </div>
                <div class="dataset-stat">
                    <div class="dataset-stat-value">~${(datasetSize * avgOutputTokens / 1000).toFixed(0)}K</div>
                    <div class="dataset-stat-label">Output Tokens</div>
                </div>
            `;

            // Calculate costs for each model
            const tbody = document.getElementById('modelCostBody');
            const totalInputTokens = datasetSize * avgInputTokens;
            const totalOutputTokens = datasetSize * avgOutputTokens;

            // Sort models: recommended first, then by cost
            const sortedModels = [...availableModels].sort((a, b) => {
                const aRec = typeConfig.recommended.includes(a.id) ? 0 : 1;
                const bRec = typeConfig.recommended.includes(b.id) ? 0 : 1;
                if (aRec !== bRec) return aRec - bRec;
                const aCost = (totalInputTokens / 1_000_000) * a.input + (totalOutputTokens / 1_000_000) * a.output;
                const bCost = (totalInputTokens / 1_000_000) * b.input + (totalOutputTokens / 1_000_000) * b.output;
                return aCost - bCost;
            });

            tbody.innerHTML = sortedModels.map(model => {
                const inputCost = (totalInputTokens / 1_000_000) * model.input;
                const outputCost = (totalOutputTokens / 1_000_000) * model.output;
                const totalCost = inputCost + outputCost;

                const isRecommended = typeConfig.recommended.includes(model.id);
                const costClass = isRecommended ? 'recommended' :
                                  totalCost < 0.10 ? 'good' :
                                  totalCost < 1.00 ? 'moderate' : 'expensive';

                const providerBadge = `<span class="model-provider-badge ${model.provider}">${model.provider === 'openai' ? 'OpenAI' : 'Google'}</span>`;

                const qualityBar = `<div style="display: flex; align-items: center; gap: 4px;">
                    <div style="width: 50px; height: 6px; background: #334155; border-radius: 3px;">
                        <div style="width: ${model.quality}%; height: 100%; background: ${model.quality >= 90 ? '#22c55e' : model.quality >= 80 ? '#3b82f6' : '#eab308'}; border-radius: 3px;"></div>
                    </div>
                    <span style="font-size: 0.7rem; color: #94a3b8;">${model.quality}</span>
                </div>`;

                const speedBar = `<div style="display: flex; align-items: center; gap: 4px;">
                    <div style="width: 50px; height: 6px; background: #334155; border-radius: 3px;">
                        <div style="width: ${model.speed}%; height: 100%; background: ${model.speed >= 90 ? '#22c55e' : model.speed >= 70 ? '#3b82f6' : '#eab308'}; border-radius: 3px;"></div>
                    </div>
                    <span style="font-size: 0.7rem; color: #94a3b8;">${model.speed}</span>
                </div>`;

                return `
                    <tr>
                        <td class="model-name">${model.name}${providerBadge}</td>
                        <td style="color: #94a3b8;">$${model.input.toFixed(2)}</td>
                        <td style="color: #94a3b8;">$${model.output.toFixed(2)}</td>
                        <td style="color: #64748b; font-size: 0.75rem;">$${(model.input + model.output).toFixed(2)}</td>
                        <td class="cost-cell ${costClass}">$${totalCost < 0.01 ? totalCost.toFixed(4) : totalCost.toFixed(2)}</td>
                        <td>${qualityBar}</td>
                        <td>${speedBar}</td>
                    </tr>
                `;
            }).join('');
        }

        // Update selectFolder to include model matrix
        const originalSelectFolder = selectFolder;
        selectFolder = function(folder) {
            document.querySelectorAll('.module-btn').forEach(btn => {
                btn.classList.toggle('active', btn.dataset.folder === folder);
            });

            const moduleRuns = progressData.filter(r => getModuleFolder(r.module) === folder);
            moduleRuns.sort((a, b) => {
                const getModuleVersion = (mod) => {
                    const match = mod.match(/_v(\d+)$/i);
                    return match ? parseInt(match[1]) : 999;
                };
                const verA = getModuleVersion(a.module);
                const verB = getModuleVersion(b.module);
                if (verA !== verB) return verA - verB;
                return a.module.localeCompare(b.module);
            });

            updateStats(moduleRuns);
            updatePassRateChart(moduleRuns);
            updateModelCompareChart(moduleRuns);
            updateProgressTable(moduleRuns);
            updateAppliedImprovements(folder, moduleRuns);
            updateSuggestions(folder, moduleRuns);
            updateModelCostMatrix(folder, moduleRuns);
        };

        initModuleSelector();
        if (folders.length > 0) selectFolder(folders[0]);
    </script>
</body>
</html>